{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlflow_run.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP4dAUz+3tgU7B8Tne8haUB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bksgupta/made-wit-ml-changes/blob/main/mlflow_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdrrsquiNkSU"
      },
      "source": [
        "from collections import Counter, OrderedDict\n",
        "import ipywidgets as widgets\n",
        "import itertools\n",
        "import json\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB-2nm6NNkSU",
        "outputId": "6d0aa30f-5c71-4410-d20b-30b359203140"
      },
      "source": [
        "# Load projects\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/MadeWithML/main/datasets/projects.json\"\n",
        "projects = json.loads(urlopen(url).read())\n",
        "print (json.dumps(projects[-305], indent=2))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": 2106,\n",
            "  \"created_on\": \"2020-08-08 15:06:18\",\n",
            "  \"title\": \"Fast NST for Videos (+ person segmentation) \\ud83c\\udfa5 + \\u26a1\\ud83d\\udcbb + \\ud83c\\udfa8 = \\u2764\\ufe0f\",\n",
            "  \"description\": \"Create NST videos and pick separate styles for the person in the video and for the background.\",\n",
            "  \"tags\": [\n",
            "    \"code\",\n",
            "    \"tutorial\",\n",
            "    \"video\",\n",
            "    \"computer-vision\",\n",
            "    \"style-transfer\",\n",
            "    \"neural-style-transfer\"\n",
            "  ]\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pJcQOR7NkSU",
        "outputId": "06bc0f6e-daca-45bb-c6c5-d4707422409d"
      },
      "source": [
        "# Load tags\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/MadeWithML/main/datasets/tags.json\"\n",
        "tags = json.loads(urlopen(url).read())\n",
        "tags_dict = {}\n",
        "for item in tags:\n",
        "    key = item.pop(\"tag\")\n",
        "    tags_dict[key] = item\n",
        "print (f\"{len(tags_dict)} tags\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400 tags\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "ZAYXvZ_TNkSU",
        "outputId": "4d1b41a4-f929-4bd5-db3f-61bd0891e0c6"
      },
      "source": [
        "# Create dataframe\n",
        "df = pd.DataFrame(projects)\n",
        "print (f\"{len(df)} projects\")\n",
        "df.head(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2032 projects\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>created_on</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2020-02-17 06:30:41</td>\n",
              "      <td>Machine Learning Basics</td>\n",
              "      <td>A practical set of notebooks on machine learni...</td>\n",
              "      <td>[code, tutorial, keras, pytorch, tensorflow, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2020-02-17 06:41:45</td>\n",
              "      <td>Deep Learning with Electronic Health Record (E...</td>\n",
              "      <td>A comprehensive look at recent machine learnin...</td>\n",
              "      <td>[article, tutorial, deep-learning, health, ehr]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2020-02-20 06:07:59</td>\n",
              "      <td>Automatic Parking Management using computer vi...</td>\n",
              "      <td>Detecting empty and parked spaces in car parki...</td>\n",
              "      <td>[code, tutorial, video, python, machine-learni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2020-02-20 06:21:57</td>\n",
              "      <td>Easy street parking using region proposal netw...</td>\n",
              "      <td>Get a text on your phone whenever a nearby par...</td>\n",
              "      <td>[code, tutorial, python, pytorch, machine-lear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2020-02-20 06:29:18</td>\n",
              "      <td>Deep Learning based parking management system ...</td>\n",
              "      <td>Fastai provides easy to use wrappers to quickl...</td>\n",
              "      <td>[code, tutorial, fastai, deep-learning, parkin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                               tags\n",
              "0   1  ...  [code, tutorial, keras, pytorch, tensorflow, d...\n",
              "1   2  ...    [article, tutorial, deep-learning, health, ehr]\n",
              "2   3  ...  [code, tutorial, video, python, machine-learni...\n",
              "3   4  ...  [code, tutorial, python, pytorch, machine-lear...\n",
              "4   5  ...  [code, tutorial, fastai, deep-learning, parkin...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIyFsybTAqFT"
      },
      "source": [
        "df[\"text\"] = df.title + \" \" + df.description"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYebjWj0Atjg"
      },
      "source": [
        "def filter(l, include=[], exclude=[]):\n",
        "    \"\"\"Filter a list using inclusion and exclusion lists of items.\"\"\"\n",
        "    filtered = [item for item in l if item in include and item not in exclude]\n",
        "    return filtered"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAK2P_bOAxOv"
      },
      "source": [
        "# Inclusion/exclusion criteria for tags\n",
        "include = list(tags_dict.keys())\n",
        "exclude = [\"machine-learning\", \"deep-learning\",  \"data-science\",\n",
        "           \"neural-networks\", \"python\", \"r\", \"visualization\", \"wandb\"]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzYljKfaAzpg"
      },
      "source": [
        "# Filter tags for each project\n",
        "df.tags = df.tags.apply(filter, include=include, exclude=exclude)\n",
        "tags = Counter(itertools.chain.from_iterable(df.tags.values))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AY4Z1diA2Oy"
      },
      "source": [
        "# Filter tags that have fewer than <min_tag_freq> occurrences\n",
        "min_tag_freq = 30\n",
        "tags_above_freq = Counter(tag for tag in tags.elements() \n",
        "                          if tags[tag] >= min_tag_freq)\n",
        "df.tags = df.tags.apply(filter, include=list(tags_above_freq.keys()))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wyNTvBkA6st"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZgqtFCeA9UC",
        "outputId": "f6f4aaa5-f371-4f3f-f808-5caa0419e09b"
      },
      "source": [
        "# Remove projects with no more remaining relevant tags\n",
        "df = df[df.tags.map(len) > 0]\n",
        "print (f\"{len(df)} projects\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1439 projects\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6u1TWmjA_qs",
        "outputId": "0da9188e-0d31-4ee2-bff1-fdcbc698d2b7"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "STOPWORDS = stopwords.words('english')\n",
        "porter = PorterStemmer()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82oYN5oiBCXz"
      },
      "source": [
        "def preprocess(text, lower=True, stem=False, \n",
        "               filters=\"[!\\\"'#$%&()*\\+,-./:;<=>?@\\\\\\[\\]^_`{|}~]\", \n",
        "               stopwords=STOPWORDS):\n",
        "    \"\"\"Conditional preprocessing on our text unique to our task.\"\"\"\n",
        "    # Lower\n",
        "    if lower: \n",
        "        text = text.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords) + r')\\b\\s*')\n",
        "    text = pattern.sub('', text)\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
        "    text = re.sub(filters, r\"\", text)\n",
        "    text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric chars\n",
        "    text = re.sub(' +', ' ', text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    # Remove links\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Stemming\n",
        "    if stem:\n",
        "        text = \" \".join([porter.stem(word) for word in text.split(' ')])\n",
        "\n",
        "    return text"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxIybzz6BHQr",
        "outputId": "e8ac34ec-f8fe-4139-ae07-edf496aa3803"
      },
      "source": [
        "# Apply to dataframe\n",
        "original_df = df.copy()\n",
        "df.text = df.text.apply(preprocess, lower=True, stem=False)\n",
        "print (f\"{original_df.text.values[0]}\\n{df.text.values[0]}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Machine Learning Basics A practical set of notebooks on machine learning basics, implemented in both TF2.0 + Keras and PyTorch.\n",
            "machine learning basics practical set notebooks machine learning basics implemented tf2 0 keras pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3cMUKh7DYt3"
      },
      "source": [
        "all_tags = list(itertools.chain.from_iterable(df.tags.values))\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IniCSpsCBKr1"
      },
      "source": [
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAQBMW_BBPvS"
      },
      "source": [
        "# Set seeds for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUbTgxa4BWkK"
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhpgg3VXBYci"
      },
      "source": [
        "# Get data\n",
        "X = df.text.to_numpy()\n",
        "y = df.tags"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opaA-mN2Bapz"
      },
      "source": [
        "class LabelEncoder(object):\n",
        "    \"\"\"Label encoder for tag labels.\"\"\"\n",
        "    def __init__(self, class_to_index={}):\n",
        "        self.class_to_index = class_to_index\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.class_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
        "\n",
        "    def fit(self, y):\n",
        "        classes = np.unique(list(itertools.chain.from_iterable(y)))\n",
        "        for i, class_ in enumerate(classes):\n",
        "            self.class_to_index[class_] = i\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "        return self\n",
        "\n",
        "    def encode(self, y):\n",
        "        y_one_hot = np.zeros((len(y), len(self.class_to_index)), dtype=int)\n",
        "        for i, item in enumerate(y):\n",
        "            for class_ in item:\n",
        "                y_one_hot[i][self.class_to_index[class_]] = 1\n",
        "        return y_one_hot\n",
        "\n",
        "    def decode(self, y):\n",
        "        classes = []\n",
        "        for i, item in enumerate(y):\n",
        "            indices = np.where(item == 1)[0]\n",
        "            classes.append([self.index_to_class[index] for index in indices])\n",
        "        return classes\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, 'w') as fp:\n",
        "            contents = {'class_to_index': self.class_to_index}\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, 'r') as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGji0ol5Belu",
        "outputId": "a3c12f9d-e15d-4816-9943-facdfe7e0620"
      },
      "source": [
        "!pip install scikit-multilearn==0.2.0 -q"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▊                            | 10kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40kB 15.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 61kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 71kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 81kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 6.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox8ZxNUkBhzi"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtF9hSRSBktm"
      },
      "source": [
        "# Split sizes\n",
        "train_size = 0.7\n",
        "val_size = 0.15\n",
        "test_size = 0.15"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmdjP-iCBmdT"
      },
      "source": [
        "from skmultilearn.model_selection import IterativeStratification"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgXm61k6BqHz"
      },
      "source": [
        "def iterative_train_test_split(X, y, train_size):\n",
        "    \"\"\"Custom iterative train test split which \n",
        "    'maintains balanced representation with respect \n",
        "    to order-th label combinations.'\n",
        "    \"\"\"\n",
        "    stratifier = IterativeStratification(\n",
        "        n_splits=2, order=1, sample_distribution_per_fold=[1.0-train_size, train_size, ])\n",
        "    train_indices, test_indices = next(stratifier.split(X, y))\n",
        "    X_train, y_train = X[train_indices], y[train_indices]\n",
        "    X_test, y_test = X[test_indices], y[test_indices]\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYiP7X2GBsIF"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import torch"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAJ-LqW1Bzs9"
      },
      "source": [
        "def set_seeds(seed=1234):\n",
        "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # multi-GPU"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HKJ9fqYB1jA"
      },
      "source": [
        "def get_data_splits(df, train_size=0.7):\n",
        "    \"\"\"\"\"\"\n",
        "    # Get data\n",
        "    X = df.text.to_numpy()\n",
        "    y = df.tags\n",
        "\n",
        "    # Binarize y\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(y)\n",
        "    y = label_encoder.encode(y)\n",
        "\n",
        "    # Split\n",
        "    X_train, X_, y_train, y_ = iterative_train_test_split(\n",
        "        X, y, train_size=train_size)\n",
        "    X_val, X_test, y_val, y_test = iterative_train_test_split(\n",
        "        X_, y_, train_size=0.5)\n",
        "    \n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test, label_encoder"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-yxZVOqB4hq"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NoUBnqJB-yV"
      },
      "source": [
        "set_seeds()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDMwRGzhCAnm"
      },
      "source": [
        "class Tokenizer(object):\n",
        "    def __init__(self, char_level, num_tokens=None, \n",
        "                 pad_token=\"<PAD>\", oov_token=\"<UNK>\",\n",
        "                 token_to_index=None):\n",
        "        self.char_level = char_level\n",
        "        self.separator = '' if self.char_level else ' '\n",
        "        if num_tokens: num_tokens -= 2 # pad + unk tokens\n",
        "        self.num_tokens = num_tokens\n",
        "        self.pad_token = pad_token\n",
        "        self.oov_token = oov_token\n",
        "        if not token_to_index:\n",
        "            token_to_index = {pad_token: 0, oov_token: 1}\n",
        "        self.token_to_index = token_to_index\n",
        "        self.index_to_token = {v: k for k, v in self.token_to_index.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        if not self.char_level:\n",
        "            texts = [text.split(\" \") for text in texts]\n",
        "        all_tokens = [token for text in texts for token in text]\n",
        "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
        "        self.min_token_freq = counts[-1][1]\n",
        "        for token, count in counts:\n",
        "            index = len(self)\n",
        "            self.token_to_index[token] = index\n",
        "            self.index_to_token[index] = token\n",
        "        return self\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        sequences = []\n",
        "        for text in texts:\n",
        "            if not self.char_level:\n",
        "                text = text.split(' ')\n",
        "            sequence = []\n",
        "            for token in text:\n",
        "                sequence.append(self.token_to_index.get(\n",
        "                    token, self.token_to_index[self.oov_token]))\n",
        "            sequences.append(np.asarray(sequence))\n",
        "        return sequences\n",
        "\n",
        "    def sequences_to_texts(self, sequences):\n",
        "        texts = []\n",
        "        for sequence in sequences:\n",
        "            text = []\n",
        "            for index in sequence:\n",
        "                text.append(self.index_to_token.get(index, self.oov_token))\n",
        "            texts.append(self.separator.join([token for token in text]))\n",
        "        return texts\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, \"w\") as fp:\n",
        "            contents = {\n",
        "                \"char_level\": self.char_level,\n",
        "                \"oov_token\": self.oov_token,\n",
        "                \"token_to_index\": self.token_to_index\n",
        "            }\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, \"r\") as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gILzfBKrCD7q"
      },
      "source": [
        "def pad_sequences(sequences, max_seq_len=0):\n",
        "    \"\"\"Pad sequences to max length in sequence.\"\"\"\n",
        "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
        "    padded_sequences = np.zeros((len(sequences), max_seq_len))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        padded_sequences[i][:len(sequence)] = sequence\n",
        "    return padded_sequences"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3onwT4X7CHqw"
      },
      "source": [
        "class CNNTextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, max_filter_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.max_filter_size = max_filter_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Dataset(N={len(self)})>\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.X[index]\n",
        "        y = self.y[index]\n",
        "        return [X, y]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        \"\"\"Processing on a batch.\"\"\"\n",
        "        # Get inputs\n",
        "        batch = np.array(batch, dtype=object)\n",
        "        X = batch[:, 0]\n",
        "        y = np.stack(batch[:, 1], axis=0)\n",
        "\n",
        "        # Pad inputs\n",
        "        X = pad_sequences(sequences=X, max_seq_len=self.max_filter_size)\n",
        "\n",
        "        # Cast\n",
        "        X = torch.LongTensor(X.astype(np.int32))\n",
        "        y = torch.FloatTensor(y.astype(np.int32))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset=self,\n",
        "            batch_size=batch_size,\n",
        "            collate_fn=self.collate_fn,\n",
        "            shuffle=shuffle,\n",
        "            drop_last=drop_last,\n",
        "            pin_memory=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa7mVPsSCJq7"
      },
      "source": [
        "# Arguments\n",
        "embedding_dim = 128\n",
        "num_filters = 128\n",
        "hidden_dim = 128\n",
        "dropout_p = 0.5"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYXtyYKtCM8T"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, vocab_size, num_filters, filter_sizes,\n",
        "                 hidden_dim, dropout_p, num_classes, padding_idx=0):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Initialize embeddings\n",
        "        self.embeddings = nn.Embedding(\n",
        "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
        "                padding_idx=padding_idx)\n",
        "\n",
        "        # Conv weights\n",
        "        self.filter_sizes = filter_sizes\n",
        "        self.conv = nn.ModuleList(\n",
        "            [nn.Conv1d(in_channels=embedding_dim,\n",
        "                       out_channels=num_filters,\n",
        "                       kernel_size=f) for f in filter_sizes])\n",
        "\n",
        "        # FC weights\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc1 = nn.Linear(num_filters*len(filter_sizes), hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs, channel_first=False):\n",
        "\n",
        "        # Embed\n",
        "        x_in, = inputs\n",
        "        x_in = self.embeddings(x_in)\n",
        "        if not channel_first:\n",
        "            x_in = x_in.transpose(1, 2)  # (N, channels, sequence length)\n",
        "\n",
        "        z = []\n",
        "        max_seq_len = x_in.shape[2]\n",
        "        for i, f in enumerate(self.filter_sizes):\n",
        "\n",
        "            # `SAME` padding\n",
        "            padding_left = int(\n",
        "                (self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2)\n",
        "            padding_right = int(math.ceil(\n",
        "                (self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2))\n",
        "\n",
        "            # Conv\n",
        "            _z = self.conv[i](F.pad(x_in, (padding_left, padding_right)))\n",
        "\n",
        "            # Pool\n",
        "            _z = F.max_pool1d(_z, _z.size(2)).squeeze(2)\n",
        "            z.append(_z)\n",
        "\n",
        "        # Concat outputs\n",
        "        z = torch.cat(z, 1)\n",
        "\n",
        "        # FC\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        z = self.fc2(z)\n",
        "\n",
        "        return z"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so4x-N4dCOpM"
      },
      "source": [
        "from pathlib import Path\n",
        "from sklearn.metrics import precision_recall_curve"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5D_7cq0CS7V"
      },
      "source": [
        "# Determining the best threshold\n",
        "def find_best_threshold(y_true, y_prob):\n",
        "    \"\"\"Find the best threshold for maximum F1.\"\"\"\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_prob)\n",
        "    f1s = (2 * precisions * recalls) / (precisions + recalls)\n",
        "    return thresholds[np.argmax(f1s)]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efBx0pL1CVpR",
        "outputId": "a4a1fc97-91bb-4667-af6e-1778843d3c33"
      },
      "source": [
        "!pip install mlflow pyngrok -q"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 14.2MB 204kB/s \n",
            "\u001b[K     |████████████████████████████████| 747kB 44.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 645kB 46.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 56.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 52.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 56.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 10.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 13.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 13.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 12.0MB/s \n",
            "\u001b[?25h  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZg01br5CpNS"
      },
      "source": [
        "from argparse import Namespace\n",
        "import mlflow\n",
        "from pathlib import Path"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vu_jUWbCrSG"
      },
      "source": [
        "# Specify arguments\n",
        "args = Namespace(\n",
        "    char_level=True,\n",
        "    filter_sizes=list(range(1, 11)),\n",
        "    batch_size=64,\n",
        "    embedding_dim=128, \n",
        "    num_filters=128,\n",
        "    hidden_dim=128, \n",
        "    dropout_p=0.5,\n",
        "    lr=2e-4,\n",
        "    num_epochs=200,\n",
        "    patience=10,\n",
        ")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3rwBJJPCvXT"
      },
      "source": [
        "# Set tracking URI\n",
        "MODEL_REGISTRY = Path(\"experiments\")\n",
        "Path(MODEL_REGISTRY).mkdir(exist_ok=True) # create experiments dir\n",
        "mlflow.set_tracking_uri(\"file://\" + str(MODEL_REGISTRY.absolute()))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFVTAXSPCyhE"
      },
      "source": [
        "# Trainer (modified for experiment tracking)\n",
        "class Trainer(object):\n",
        "    def __init__(self, model, device, loss_fn=None, \n",
        "                 optimizer=None, scheduler=None):\n",
        "\n",
        "        # Set params\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        \"\"\"Train step.\"\"\"\n",
        "        # Set model to train mode\n",
        "        self.model.train()\n",
        "        loss = 0.0\n",
        "\n",
        "        # Iterate over train batches\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            # Step\n",
        "            batch = [item.to(self.device) for item in batch]\n",
        "            inputs, targets = batch[:-1], batch[-1]\n",
        "            self.optimizer.zero_grad()  # Reset gradients\n",
        "            z = self.model(inputs)  # Forward pass\n",
        "            J = self.loss_fn(z, targets)  # Define loss\n",
        "            J.backward()  # Backward pass\n",
        "            self.optimizer.step()  # Update weights\n",
        "\n",
        "            # Cumulative Metrics\n",
        "            loss += (J.detach().item() - loss) / (i + 1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def eval_step(self, dataloader):\n",
        "        \"\"\"Validation or test step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        y_trues, y_probs = [], []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Step\n",
        "                batch = [item.to(self.device) for item in batch]  # Set device\n",
        "                inputs, y_true = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)  # Forward pass\n",
        "                J = self.loss_fn(z, y_true).item()\n",
        "\n",
        "                # Cumulative Metrics\n",
        "                loss += (J - loss) / (i + 1)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = torch.sigmoid(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "                y_trues.extend(y_true.cpu().numpy())\n",
        "\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "    def predict_step(self, dataloader):\n",
        "        \"\"\"Prediction step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        y_probs = []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Forward pass w/ inputs\n",
        "                inputs, targets = batch[:-1], batch[-1]\n",
        "                y_prob = self.model(inputs)\n",
        "\n",
        "                # Store outputs\n",
        "                y_probs.extend(y_prob)\n",
        "\n",
        "        return np.vstack(y_probs)\n",
        "    \n",
        "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
        "        best_val_loss = np.inf\n",
        "        for epoch in range(num_epochs):\n",
        "            # Steps\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = self.model\n",
        "                _patience = patience  # reset _patience\n",
        "            else:\n",
        "                _patience -= 1\n",
        "            if not _patience:  # 0\n",
        "                print(\"Stopping early!\")\n",
        "                break\n",
        "\n",
        "            # Tracking\n",
        "            mlflow.log_metrics(\n",
        "                {\"train_loss\": train_loss, \"val_loss\": val_loss}, step=epoch\n",
        "            )\n",
        "\n",
        "            # Logging\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1} | \"\n",
        "                f\"train_loss: {train_loss:.5f}, \"\n",
        "                f\"val_loss: {val_loss:.5f}, \"\n",
        "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "                f\"_patience: {_patience}\"\n",
        "            )\n",
        "\n",
        "        return best_model, best_val_loss"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtyDaeJ8C4VA"
      },
      "source": [
        "def train_cnn(args, df):\n",
        "    \"\"\"Train a CNN using specific arguments.\"\"\"\n",
        "\n",
        "    # Set seeds\n",
        "    set_seeds()\n",
        "\n",
        "    # Get data splits\n",
        "    preprocessed_df = df.copy()\n",
        "    preprocessed_df.text = preprocessed_df.text.apply(preprocess, lower=True)\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test, label_encoder = get_data_splits(preprocessed_df)\n",
        "    num_classes = len(label_encoder)\n",
        "\n",
        "    # Set device\n",
        "    cuda = True\n",
        "    device = torch.device(\"cuda\" if (\n",
        "        torch.cuda.is_available() and cuda) else \"cpu\")\n",
        "    torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
        "    if device.type == \"cuda\":\n",
        "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "\n",
        "    # Tokenize\n",
        "    tokenizer = Tokenizer(char_level=args.char_level)\n",
        "    tokenizer.fit_on_texts(texts=X_train)\n",
        "    vocab_size = len(tokenizer)\n",
        "\n",
        "    # Convert texts to sequences of indices\n",
        "    X_train = np.array(tokenizer.texts_to_sequences(X_train))\n",
        "    X_val = np.array(tokenizer.texts_to_sequences(X_val))\n",
        "    X_test = np.array(tokenizer.texts_to_sequences(X_test))\n",
        "\n",
        "    # Class weights\n",
        "    counts = np.bincount([label_encoder.class_to_index[class_] for class_ in all_tags])\n",
        "    class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = CNNTextDataset(\n",
        "        X=X_train, y=y_train, max_filter_size=max(args.filter_sizes))\n",
        "    val_dataset = CNNTextDataset(\n",
        "        X=X_val, y=y_val, max_filter_size=max(args.filter_sizes))\n",
        "    test_dataset = CNNTextDataset(\n",
        "        X=X_test, y=y_test, max_filter_size=max(args.filter_sizes))\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_dataloader = train_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "    val_dataloader = val_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "    test_dataloader = test_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "\n",
        "    # Initialize model\n",
        "    model = CNN(\n",
        "        embedding_dim=args.embedding_dim, vocab_size=vocab_size,\n",
        "        num_filters=args.num_filters, filter_sizes=args.filter_sizes,\n",
        "        hidden_dim=args.hidden_dim, dropout_p=args.dropout_p,\n",
        "        num_classes=num_classes)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define loss\n",
        "    class_weights_tensor = torch.Tensor(np.array(list(class_weights.values())))\n",
        "    loss_fn = nn.BCEWithLogitsLoss(weight=class_weights_tensor)\n",
        "\n",
        "    # Define optimizer & scheduler\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode=\"min\", factor=0.1, patience=5)\n",
        "\n",
        "    # Trainer module\n",
        "    trainer = Trainer(\n",
        "        model=model, device=device, loss_fn=loss_fn, \n",
        "        optimizer=optimizer, scheduler=scheduler)\n",
        "\n",
        "    # Train\n",
        "    best_model, best_val_loss = trainer.train(\n",
        "        args.num_epochs, args.patience, train_dataloader, val_dataloader)\n",
        "\n",
        "    # Best threshold for f1\n",
        "    train_loss, y_true, y_prob = trainer.eval_step(dataloader=train_dataloader)\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_true.ravel(), y_prob.ravel())\n",
        "    threshold = find_best_threshold(y_true.ravel(), y_prob.ravel())\n",
        "\n",
        "    # Determine predictions using threshold\n",
        "    test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "    y_pred = np.array([np.where(prob >= threshold, 1, 0) for prob in y_prob])\n",
        "\n",
        "    # Evaluate (simple)\n",
        "    metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
        "    performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
        "    threshold_dict={\"thresh\": str(threshold)}\n",
        "    return {\n",
        "        \"args\": args,\n",
        "        \"tokenizer\": tokenizer,\n",
        "        \"label_encoder\": label_encoder,\n",
        "        \"model\": best_model,\n",
        "        \"performance\": performance,\n",
        "        \"best_val_loss\": best_val_loss,\n",
        "        \"threshold\": threshold_dict,\n",
        "    }"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWS5ShrEC7Hy"
      },
      "source": [
        "import tempfile"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2lqmNJTC9kw",
        "outputId": "f3ddaf09-7da5-4518-9593-7e1a2960f6eb"
      },
      "source": [
        "# Set experiment\n",
        "mlflow.set_experiment(experiment_name=\"baselines\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: 'baselines' does not exist. Creating a new experiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zFVH_X6DACE"
      },
      "source": [
        "def save_dict(d, filepath):\n",
        "    \"\"\"Save dict to a json file.\"\"\"\n",
        "    with open(filepath, \"w\") as fp:\n",
        "        json.dump(d, indent=2, sort_keys=False, fp=fp)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC0jPwz_DC9E",
        "outputId": "c3e1084b-1f1c-4106-fd6a-ea9e20d5d00c"
      },
      "source": [
        "# Tracking\n",
        "with mlflow.start_run(run_name=\"cnn\") as run:\n",
        "\n",
        "    # Train & evaluate\n",
        "    artifacts = train_cnn(args=args, df=df)    \n",
        "    \n",
        "    # Log key metrics\n",
        "    #mlflow.log_metrics({\"precision\": artifacts[\"performance\"][\"overall\"][\"precision\"]})\n",
        "    mlflow.log_metrics({\"precision\": artifacts[\"performance\"][\"precision\"]})\n",
        "    #mlflow.log_metrics({\"recall\": artifacts[\"performance\"][\"overall\"][\"recall\"]})\n",
        "    mlflow.log_metrics({\"recall\": artifacts[\"performance\"][\"recall\"]})\n",
        "    #mlflow.log_metrics({\"f1\": artifacts[\"performance\"][\"overall\"][\"f1\"]})\n",
        "    mlflow.log_metrics({\"f1\": artifacts[\"performance\"][\"f1\"]})\n",
        "\n",
        "    # Log artifacts\n",
        "    with tempfile.TemporaryDirectory() as dp:\n",
        "        artifacts[\"tokenizer\"].save(Path(dp, \"tokenizer.json\"))\n",
        "        artifacts[\"label_encoder\"].save(Path(dp, \"label_encoder.json\"))\n",
        "        torch.save(artifacts[\"model\"].state_dict(), Path(dp, \"model.pt\"))\n",
        "        save_dict(artifacts[\"performance\"], Path(dp, \"performance.json\"))\n",
        "        save_dict(artifacts[\"threshold\"][\"thresh\"], Path(dp, \"threshold.json\"))\n",
        "        mlflow.log_artifacts(dp)\n",
        "\n",
        "    # Log parameters\n",
        "    mlflow.log_params(vars(artifacts[\"args\"]))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00533, val_loss: 0.00307, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00385, val_loss: 0.00287, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00347, val_loss: 0.00269, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00324, val_loss: 0.00265, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00307, val_loss: 0.00259, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00297, val_loss: 0.00253, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00285, val_loss: 0.00247, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00273, val_loss: 0.00240, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00263, val_loss: 0.00233, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00249, val_loss: 0.00224, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00238, val_loss: 0.00216, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00229, val_loss: 0.00211, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00218, val_loss: 0.00205, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00206, val_loss: 0.00196, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00194, val_loss: 0.00192, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00187, val_loss: 0.00186, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00181, val_loss: 0.00180, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00174, val_loss: 0.00179, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00165, val_loss: 0.00177, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00158, val_loss: 0.00172, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00151, val_loss: 0.00169, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00145, val_loss: 0.00170, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 23 | train_loss: 0.00141, val_loss: 0.00163, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00136, val_loss: 0.00161, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00129, val_loss: 0.00163, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00125, val_loss: 0.00161, lr: 2.00E-04, _patience: 8\n",
            "Epoch: 27 | train_loss: 0.00119, val_loss: 0.00158, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00116, val_loss: 0.00156, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00111, val_loss: 0.00158, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 30 | train_loss: 0.00109, val_loss: 0.00161, lr: 2.00E-04, _patience: 8\n",
            "Epoch: 31 | train_loss: 0.00104, val_loss: 0.00155, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00100, val_loss: 0.00157, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 33 | train_loss: 0.00096, val_loss: 0.00157, lr: 2.00E-04, _patience: 8\n",
            "Epoch: 34 | train_loss: 0.00093, val_loss: 0.00152, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 35 | train_loss: 0.00089, val_loss: 0.00152, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 36 | train_loss: 0.00088, val_loss: 0.00153, lr: 2.00E-04, _patience: 8\n",
            "Epoch: 37 | train_loss: 0.00084, val_loss: 0.00152, lr: 2.00E-04, _patience: 7\n",
            "Epoch: 38 | train_loss: 0.00080, val_loss: 0.00159, lr: 2.00E-04, _patience: 6\n",
            "Epoch: 39 | train_loss: 0.00079, val_loss: 0.00153, lr: 2.00E-04, _patience: 5\n",
            "Epoch: 40 | train_loss: 0.00077, val_loss: 0.00158, lr: 2.00E-05, _patience: 4\n",
            "Epoch: 41 | train_loss: 0.00070, val_loss: 0.00148, lr: 2.00E-05, _patience: 10\n",
            "Epoch: 42 | train_loss: 0.00072, val_loss: 0.00150, lr: 2.00E-05, _patience: 9\n",
            "Epoch: 43 | train_loss: 0.00070, val_loss: 0.00147, lr: 2.00E-05, _patience: 10\n",
            "Epoch: 44 | train_loss: 0.00068, val_loss: 0.00150, lr: 2.00E-05, _patience: 9\n",
            "Epoch: 45 | train_loss: 0.00070, val_loss: 0.00149, lr: 2.00E-05, _patience: 8\n",
            "Epoch: 46 | train_loss: 0.00068, val_loss: 0.00150, lr: 2.00E-05, _patience: 7\n",
            "Epoch: 47 | train_loss: 0.00066, val_loss: 0.00150, lr: 2.00E-05, _patience: 6\n",
            "Epoch: 48 | train_loss: 0.00066, val_loss: 0.00148, lr: 2.00E-05, _patience: 5\n",
            "Epoch: 49 | train_loss: 0.00067, val_loss: 0.00149, lr: 2.00E-06, _patience: 4\n",
            "Epoch: 50 | train_loss: 0.00066, val_loss: 0.00149, lr: 2.00E-06, _patience: 3\n",
            "Epoch: 51 | train_loss: 0.00066, val_loss: 0.00150, lr: 2.00E-06, _patience: 2\n",
            "Epoch: 52 | train_loss: 0.00067, val_loss: 0.00150, lr: 2.00E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siPYbWHIDG_Y"
      },
      "source": [
        "from pyngrok import ngrok"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppkWEVqXFIKC",
        "outputId": "e42dc332-d43f-4636-ab1b-425ba987216f"
      },
      "source": [
        "# https://stackoverflow.com/questions/61615818/setting-up-mlflow-on-google-colab\n",
        "get_ipython().system_raw(\"mlflow server -h 0.0.0.0 -p 5000 --backend-store-uri $PWD/experiments/ &\")\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token(\"\")\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLflow Tracking UI: https://7cc201a91b7a.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMxiv4SOFMVm"
      },
      "source": [
        "def load_dict(filepath):\n",
        "    \"\"\"Load a dict from a json file.\"\"\"\n",
        "    with open(filepath, \"r\") as fp:\n",
        "        d = json.load(fp)\n",
        "    return d"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L17hFJboHe49",
        "outputId": "d56c287b-32bd-4c6e-dcb5-f29b24cd44e3"
      },
      "source": [
        "# Load all runs from experiment\n",
        "experiment_id = mlflow.get_experiment_by_name(\"baselines\").experiment_id\n",
        "all_runs = mlflow.search_runs(experiment_ids=experiment_id, order_by=[\"metrics.best_val_loss ASC\"])\n",
        "print (all_runs)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                             run_id  ... tags.mlflow.runName\n",
            "0  c4afb73c0b504fabb18433f1718ac727  ...                 cnn\n",
            "\n",
            "[1 rows x 25 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gOW8cMxIfGP"
      },
      "source": [
        "# Best run\n",
        "device = torch.device(\"cpu\")\n",
        "best_run_id = all_runs.iloc[0].run_id\n",
        "best_run = mlflow.get_run(run_id=best_run_id)\n",
        "client = mlflow.tracking.MlflowClient()\n",
        "with tempfile.TemporaryDirectory() as dp:\n",
        "    client.download_artifacts(run_id=best_run_id, path=\"\", dst_path=dp)\n",
        "    tokenizer = Tokenizer.load(fp=Path(dp, \"tokenizer.json\"))\n",
        "    label_encoder = LabelEncoder.load(fp=Path(dp, \"label_encoder.json\"))\n",
        "    model_state = torch.load(Path(dp, \"model.pt\"), map_location=device)\n",
        "    performance = load_dict(filepath=Path(dp, \"performance.json\"))\n",
        "    threshold = load_dict(filepath=Path(dp, \"threshold.json\"))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-KUZqD0NG_Z",
        "outputId": "bac23776-2859-486f-a66d-3d58191b6925"
      },
      "source": [
        "print (json.dumps(performance, indent=2))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.7885779643550789,\n",
            "  \"recall\": 0.5708154506437768,\n",
            "  \"f1\": 0.6391557453268072\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6naodTaNhEz",
        "outputId": "35eb3bff-0f7e-4fa2-c11d-71e5bd359291"
      },
      "source": [
        "# Load artifacts\n",
        "device = torch.device(\"cpu\")\n",
        "model = CNN(\n",
        "    embedding_dim=args.embedding_dim, vocab_size=len(tokenizer),\n",
        "    num_filters=args.num_filters, filter_sizes=args.filter_sizes,\n",
        "    hidden_dim=args.hidden_dim, dropout_p=args.dropout_p,\n",
        "    num_classes=len(label_encoder))\n",
        "model.load_state_dict(model_state)\n",
        "model.to(device)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (embeddings): Embedding(39, 128, padding_idx=0)\n",
              "  (conv): ModuleList(\n",
              "    (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
              "    (1): Conv1d(128, 128, kernel_size=(2,), stride=(1,))\n",
              "    (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
              "    (3): Conv1d(128, 128, kernel_size=(4,), stride=(1,))\n",
              "    (4): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
              "    (5): Conv1d(128, 128, kernel_size=(6,), stride=(1,))\n",
              "    (6): Conv1d(128, 128, kernel_size=(7,), stride=(1,))\n",
              "    (7): Conv1d(128, 128, kernel_size=(8,), stride=(1,))\n",
              "    (8): Conv1d(128, 128, kernel_size=(9,), stride=(1,))\n",
              "    (9): Conv1d(128, 128, kernel_size=(10,), stride=(1,))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=1280, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=34, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdUDxG8zNnoV"
      },
      "source": [
        "trainer = Trainer(model=model, device=device)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lZ_DmsPNqsl"
      },
      "source": [
        "# Dataloader\n",
        "text = \"Transfer learning with BERT for self-supervised learning\"\n",
        "X = np.array(tokenizer.texts_to_sequences([preprocess(text)]))\n",
        "y_filler = label_encoder.encode([np.array([label_encoder.classes[0]]*len(X))])\n",
        "dataset = CNNTextDataset(\n",
        "    X=X, y=y_filler, max_filter_size=max(args.filter_sizes))\n",
        "dataloader = dataset.create_dataloader(\n",
        "    batch_size=args.batch_size)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeGyCyF0VVkI",
        "outputId": "6197c324-af03-4c07-c19b-cd0e50913147"
      },
      "source": [
        "print (json.dumps(threshold, indent=2))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"0.27691326\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF5CFZNHXtzm"
      },
      "source": [
        "import decimal\n",
        "threshold_val = json.loads(threshold, parse_float = decimal.Decimal)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsR9V0ayYCBs",
        "outputId": "078e39b7-94a7-4a18-caa2-5c719184dc81"
      },
      "source": [
        "threshold_val"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Decimal('0.27691326')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjNCXXwTYDZ9"
      },
      "source": [
        "if 0.0279 > threshold_val:\n",
        "  print ('he')"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "493oLEoDNtjg",
        "outputId": "354092b6-af7c-4d29-b20a-c6866b8aaf5a"
      },
      "source": [
        "# Inference\n",
        "y_prob = trainer.predict_step(dataloader)\n",
        "y_pred = np.array([np.where(prob >= threshold_val, 1, 0) for prob in y_prob])\n",
        "label_encoder.decode(y_pred)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['natural-language-processing',\n",
              "  'self-supervised-learning',\n",
              "  'transfer-learning',\n",
              "  'transformers']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeZ9ztR7OCcf",
        "outputId": "e01c948f-26b7-439a-9a24-4916fa9f3417"
      },
      "source": [
        "!pip install optuna numpyencoder -q"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 307kB 6.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 12.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 55.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 59.7MB/s \n",
            "\u001b[?25h  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpkjMqWNarvO"
      },
      "source": [
        "import optuna"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPUQExjfawft"
      },
      "source": [
        "from argparse import Namespace"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnQcZ_qKbRaO"
      },
      "source": [
        "# Specify arguments\n",
        "args = Namespace(\n",
        "    char_level=True,\n",
        "    filter_sizes=list(range(1, 11)),\n",
        "    batch_size=64,\n",
        "    embedding_dim=128, \n",
        "    num_filters=128,\n",
        "    hidden_dim=128, \n",
        "    dropout_p=0.5,\n",
        "    lr=2e-4,\n",
        "    num_epochs=200,\n",
        "    patience=10,\n",
        ")"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_FlyhJqbUKc"
      },
      "source": [
        "# Trainer (modified for experiment tracking)\n",
        "class Trainer(object):\n",
        "    def __init__(self, model, device, loss_fn=None, \n",
        "                 optimizer=None, scheduler=None, trial=None):\n",
        "\n",
        "        # Set params\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.trial = trial\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        \"\"\"Train step.\"\"\"\n",
        "        # Set model to train mode\n",
        "        self.model.train()\n",
        "        loss = 0.0\n",
        "\n",
        "        # Iterate over train batches\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            # Step\n",
        "            batch = [item.to(self.device) for item in batch]\n",
        "            inputs, targets = batch[:-1], batch[-1]\n",
        "            self.optimizer.zero_grad()  # Reset gradients\n",
        "            z = self.model(inputs)  # Forward pass\n",
        "            J = self.loss_fn(z, targets)  # Define loss\n",
        "            J.backward()  # Backward pass\n",
        "            self.optimizer.step()  # Update weights\n",
        "\n",
        "            # Cumulative Metrics\n",
        "            loss += (J.detach().item() - loss) / (i + 1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def eval_step(self, dataloader):\n",
        "        \"\"\"Validation or test step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        y_trues, y_probs = [], []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Step\n",
        "                batch = [item.to(self.device) for item in batch]  # Set device\n",
        "                inputs, y_true = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)  # Forward pass\n",
        "                J = self.loss_fn(z, y_true).item()\n",
        "\n",
        "                # Cumulative Metrics\n",
        "                loss += (J - loss) / (i + 1)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = torch.sigmoid(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "                y_trues.extend(y_true.cpu().numpy())\n",
        "\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "    def predict_step(self, dataloader):\n",
        "        \"\"\"Prediction step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        y_probs = []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Forward pass w/ inputs\n",
        "                inputs, targets = batch[:-1], batch[-1]\n",
        "                y_prob = self.model(inputs)\n",
        "\n",
        "                # Store outputs\n",
        "                y_probs.extend(y_prob)\n",
        "\n",
        "        return np.vstack(y_probs)\n",
        "    \n",
        "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
        "        best_val_loss = np.inf\n",
        "        for epoch in range(num_epochs):\n",
        "            # Steps\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = self.model\n",
        "                _patience = patience  # reset _patience\n",
        "            else:\n",
        "                _patience -= 1\n",
        "            if not _patience:  # 0\n",
        "                print(\"Stopping early!\")\n",
        "                break\n",
        "\n",
        "            # Logging\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1} | \"\n",
        "                f\"train_loss: {train_loss:.5f}, \"\n",
        "                f\"val_loss: {val_loss:.5f}, \"\n",
        "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "                f\"_patience: {_patience}\"\n",
        "            )\n",
        "\n",
        "            # Pruning based on the intermediate value\n",
        "            self.trial.report(val_loss, epoch)\n",
        "            if self.trial.should_prune():\n",
        "                raise optuna.TrialPruned()\n",
        "                    \n",
        "        return best_model, best_val_loss"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRn2cU1mcC1N"
      },
      "source": [
        "def train_cnn(args, df, trial=None):\n",
        "    \"\"\"Train a CNN using specific arguments.\"\"\"\n",
        "\n",
        "    # Set seeds\n",
        "    set_seeds()\n",
        "\n",
        "    # Get data splits\n",
        "    preprocessed_df = df.copy()\n",
        "    preprocessed_df.text = preprocessed_df.text.apply(preprocess, lower=True)\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test, label_encoder = get_data_splits(preprocessed_df)\n",
        "    num_classes = len(label_encoder)\n",
        "\n",
        "    # Set device\n",
        "    cuda = True\n",
        "    device = torch.device(\"cuda\" if (\n",
        "        torch.cuda.is_available() and cuda) else \"cpu\")\n",
        "    torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
        "    if device.type == \"cuda\":\n",
        "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "\n",
        "    # Tokenize\n",
        "    tokenizer = Tokenizer(char_level=args.char_level)\n",
        "    tokenizer.fit_on_texts(texts=X_train)\n",
        "    vocab_size = len(tokenizer)\n",
        "\n",
        "    # Convert texts to sequences of indices\n",
        "    X_train = np.array(tokenizer.texts_to_sequences(X_train))\n",
        "    X_val = np.array(tokenizer.texts_to_sequences(X_val))\n",
        "    X_test = np.array(tokenizer.texts_to_sequences(X_test))\n",
        "\n",
        "    # Class weights\n",
        "    counts = np.bincount([label_encoder.class_to_index[class_] for class_ in all_tags])\n",
        "    class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = CNNTextDataset(\n",
        "        X=X_train, y=y_train, max_filter_size=max(args.filter_sizes))\n",
        "    val_dataset = CNNTextDataset(\n",
        "        X=X_val, y=y_val, max_filter_size=max(args.filter_sizes))\n",
        "    test_dataset = CNNTextDataset(\n",
        "        X=X_test, y=y_test, max_filter_size=max(args.filter_sizes))\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_dataloader = train_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "    val_dataloader = val_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "    test_dataloader = test_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "\n",
        "    # Initialize model\n",
        "    model = CNN(\n",
        "        embedding_dim=args.embedding_dim, vocab_size=vocab_size,\n",
        "        num_filters=args.num_filters, filter_sizes=args.filter_sizes,\n",
        "        hidden_dim=args.hidden_dim, dropout_p=args.dropout_p,\n",
        "        num_classes=num_classes)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define loss\n",
        "    class_weights_tensor = torch.Tensor(np.array(list(class_weights.values())))\n",
        "    loss_fn = nn.BCEWithLogitsLoss(weight=class_weights_tensor)\n",
        "\n",
        "    # Define optimizer & scheduler\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "    # Trainer module\n",
        "    trainer = Trainer(\n",
        "        model=model, device=device, loss_fn=loss_fn, \n",
        "        optimizer=optimizer, scheduler=scheduler, trial=trial)\n",
        "\n",
        "    # Train\n",
        "    best_model, best_val_loss = trainer.train(\n",
        "        args.num_epochs, args.patience, train_dataloader, val_dataloader)\n",
        "\n",
        "    # Best threshold for f1\n",
        "    train_loss, y_true, y_prob = trainer.eval_step(dataloader=train_dataloader)\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_true.ravel(), y_prob.ravel())\n",
        "    threshold = find_best_threshold(y_true.ravel(), y_prob.ravel())\n",
        "\n",
        "    # Determine predictions using threshold\n",
        "    test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "    y_pred = np.array([np.where(prob >= threshold, 1, 0) for prob in y_prob])\n",
        "\n",
        "    # Evaluate (simple)\n",
        "    metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
        "    performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
        "\n",
        "    return {\n",
        "        \"args\": args,\n",
        "        \"tokenizer\": tokenizer,\n",
        "        \"label_encoder\": label_encoder,\n",
        "        \"model\": best_model,\n",
        "        \"performance\": performance,\n",
        "        \"best_val_loss\": best_val_loss,\n",
        "        \"threshold\": threshold,\n",
        "    }"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R69NIFWcDol"
      },
      "source": [
        "def objective(trial, args):\n",
        "    \"\"\"Objective function for optimization trials.\"\"\"\n",
        "\n",
        "    # Paramters (to tune)\n",
        "    args.embedding_dim = trial.suggest_int(\"embedding_dim\", 128, 512)\n",
        "    args.num_filters = trial.suggest_int(\"num_filters\", 128, 512)\n",
        "    args.hidden_dim = trial.suggest_int(\"hidden_dim\", 128, 512)\n",
        "    args.dropout_p = trial.suggest_uniform(\"dropout_p\", 0.3, 0.8)\n",
        "    args.lr = trial.suggest_loguniform(\"lr\", 5e-5, 5e-4)\n",
        "\n",
        "    # Train & evaluate\n",
        "    artifacts = train_cnn(args=args, df=df, trial=trial)\n",
        "\n",
        "    # Set additional attributes\n",
        "    trial.set_user_attr(\"precision\", artifacts[\"performance\"][\"precision\"])\n",
        "    trial.set_user_attr(\"recall\", artifacts[\"performance\"][\"recall\"])\n",
        "    trial.set_user_attr(\"f1\", artifacts[\"performance\"][\"f1\"])\n",
        "    trial.set_user_attr(\"threshold\", artifacts[\"threshold\"])\n",
        "\n",
        "    return artifacts[\"performance\"][\"f1\"]"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqH4TyVecZxG"
      },
      "source": [
        "from numpyencoder import NumpyEncoder\n",
        "from optuna.integration.mlflow import MLflowCallback"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvWJOkiGceMe"
      },
      "source": [
        "NUM_TRIALS = 50 # small sample for now"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aINU8OjUchWm",
        "outputId": "211a5d03-f5fb-441d-e9c1-5fb05eb04be9"
      },
      "source": [
        "# Optimize\n",
        "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5)\n",
        "study = optuna.create_study(study_name=\"optimization\", direction=\"maximize\", pruner=pruner)\n",
        "mlflow_callback = MLflowCallback(\n",
        "    tracking_uri=mlflow.get_tracking_uri(), metric_name=\"f1\")\n",
        "study.optimize(lambda trial: objective(trial, args),\n",
        "               n_trials=NUM_TRIALS,\n",
        "               callbacks=[mlflow_callback])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-10 21:21:25,233]\u001b[0m A new study created in memory with name: optimization\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: ExperimentalWarning:\n",
            "\n",
            "MLflowCallback is experimental (supported from v1.4.0). The interface can change in the future.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00472, val_loss: 0.00348, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00362, val_loss: 0.00268, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00318, val_loss: 0.00258, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00298, val_loss: 0.00250, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00277, val_loss: 0.00238, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00263, val_loss: 0.00230, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00245, val_loss: 0.00219, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00230, val_loss: 0.00210, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00217, val_loss: 0.00199, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00202, val_loss: 0.00191, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00188, val_loss: 0.00185, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00178, val_loss: 0.00181, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00171, val_loss: 0.00177, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00158, val_loss: 0.00171, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00150, val_loss: 0.00169, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00146, val_loss: 0.00166, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00135, val_loss: 0.00161, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00130, val_loss: 0.00160, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00119, val_loss: 0.00160, lr: 1.26E-04, _patience: 9\n",
            "Epoch: 20 | train_loss: 0.00116, val_loss: 0.00158, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00111, val_loss: 0.00156, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00104, val_loss: 0.00160, lr: 1.26E-04, _patience: 9\n",
            "Epoch: 23 | train_loss: 0.00100, val_loss: 0.00153, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00093, val_loss: 0.00153, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00089, val_loss: 0.00160, lr: 1.26E-04, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00083, val_loss: 0.00154, lr: 1.26E-04, _patience: 8\n",
            "Epoch: 27 | train_loss: 0.00079, val_loss: 0.00152, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00076, val_loss: 0.00159, lr: 1.26E-04, _patience: 9\n",
            "Epoch: 29 | train_loss: 0.00075, val_loss: 0.00150, lr: 1.26E-04, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00069, val_loss: 0.00158, lr: 1.26E-04, _patience: 9\n",
            "Epoch: 31 | train_loss: 0.00066, val_loss: 0.00155, lr: 1.26E-04, _patience: 8\n",
            "Epoch: 32 | train_loss: 0.00063, val_loss: 0.00152, lr: 1.26E-04, _patience: 7\n",
            "Epoch: 33 | train_loss: 0.00060, val_loss: 0.00158, lr: 1.26E-04, _patience: 6\n",
            "Epoch: 34 | train_loss: 0.00057, val_loss: 0.00157, lr: 1.26E-04, _patience: 5\n",
            "Epoch: 35 | train_loss: 0.00055, val_loss: 0.00154, lr: 1.26E-05, _patience: 4\n",
            "Epoch: 36 | train_loss: 0.00051, val_loss: 0.00147, lr: 1.26E-05, _patience: 10\n",
            "Epoch: 37 | train_loss: 0.00049, val_loss: 0.00148, lr: 1.26E-05, _patience: 9\n",
            "Epoch: 38 | train_loss: 0.00049, val_loss: 0.00147, lr: 1.26E-05, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00047, val_loss: 0.00146, lr: 1.26E-05, _patience: 10\n",
            "Epoch: 40 | train_loss: 0.00047, val_loss: 0.00147, lr: 1.26E-05, _patience: 9\n",
            "Epoch: 41 | train_loss: 0.00046, val_loss: 0.00148, lr: 1.26E-05, _patience: 8\n",
            "Epoch: 42 | train_loss: 0.00047, val_loss: 0.00146, lr: 1.26E-05, _patience: 7\n",
            "Epoch: 43 | train_loss: 0.00047, val_loss: 0.00148, lr: 1.26E-05, _patience: 6\n",
            "Epoch: 44 | train_loss: 0.00047, val_loss: 0.00146, lr: 1.26E-05, _patience: 5\n",
            "Epoch: 45 | train_loss: 0.00046, val_loss: 0.00147, lr: 1.26E-06, _patience: 4\n",
            "Epoch: 46 | train_loss: 0.00046, val_loss: 0.00147, lr: 1.26E-06, _patience: 3\n",
            "Epoch: 47 | train_loss: 0.00046, val_loss: 0.00148, lr: 1.26E-06, _patience: 2\n",
            "Epoch: 48 | train_loss: 0.00046, val_loss: 0.00148, lr: 1.26E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:22:39,265]\u001b[0m Trial 0 finished with value: 0.6628035246740483 and parameters: {'embedding_dim': 225, 'num_filters': 287, 'hidden_dim': 240, 'dropout_p': 0.5093488542487961, 'lr': 0.00012613377731725462}. Best is trial 0 with value: 0.6628035246740483.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO: 'optimization' does not exist. Creating a new experiment\n",
            "Epoch: 1 | train_loss: 0.00542, val_loss: 0.00346, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00420, val_loss: 0.00269, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00358, val_loss: 0.00255, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00330, val_loss: 0.00247, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00306, val_loss: 0.00240, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00287, val_loss: 0.00230, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00272, val_loss: 0.00220, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00257, val_loss: 0.00212, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00246, val_loss: 0.00208, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00230, val_loss: 0.00199, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00219, val_loss: 0.00191, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00202, val_loss: 0.00188, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00195, val_loss: 0.00187, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00182, val_loss: 0.00182, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00178, val_loss: 0.00175, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00171, val_loss: 0.00172, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00160, val_loss: 0.00172, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00151, val_loss: 0.00170, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00145, val_loss: 0.00167, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00140, val_loss: 0.00165, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00135, val_loss: 0.00163, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00130, val_loss: 0.00169, lr: 7.75E-05, _patience: 9\n",
            "Epoch: 23 | train_loss: 0.00125, val_loss: 0.00167, lr: 7.75E-05, _patience: 8\n",
            "Epoch: 24 | train_loss: 0.00120, val_loss: 0.00168, lr: 7.75E-05, _patience: 7\n",
            "Epoch: 25 | train_loss: 0.00114, val_loss: 0.00161, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00108, val_loss: 0.00154, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00103, val_loss: 0.00161, lr: 7.75E-05, _patience: 9\n",
            "Epoch: 28 | train_loss: 0.00100, val_loss: 0.00159, lr: 7.75E-05, _patience: 8\n",
            "Epoch: 29 | train_loss: 0.00094, val_loss: 0.00155, lr: 7.75E-05, _patience: 7\n",
            "Epoch: 30 | train_loss: 0.00093, val_loss: 0.00151, lr: 7.75E-05, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00090, val_loss: 0.00158, lr: 7.75E-05, _patience: 9\n",
            "Epoch: 32 | train_loss: 0.00083, val_loss: 0.00157, lr: 7.75E-05, _patience: 8\n",
            "Epoch: 33 | train_loss: 0.00081, val_loss: 0.00153, lr: 7.75E-05, _patience: 7\n",
            "Epoch: 34 | train_loss: 0.00080, val_loss: 0.00160, lr: 7.75E-05, _patience: 6\n",
            "Epoch: 35 | train_loss: 0.00076, val_loss: 0.00157, lr: 7.75E-05, _patience: 5\n",
            "Epoch: 36 | train_loss: 0.00076, val_loss: 0.00157, lr: 7.75E-06, _patience: 4\n",
            "Epoch: 37 | train_loss: 0.00070, val_loss: 0.00148, lr: 7.75E-06, _patience: 10\n",
            "Epoch: 38 | train_loss: 0.00069, val_loss: 0.00149, lr: 7.75E-06, _patience: 9\n",
            "Epoch: 39 | train_loss: 0.00065, val_loss: 0.00149, lr: 7.75E-06, _patience: 8\n",
            "Epoch: 40 | train_loss: 0.00063, val_loss: 0.00147, lr: 7.75E-06, _patience: 10\n",
            "Epoch: 41 | train_loss: 0.00061, val_loss: 0.00148, lr: 7.75E-06, _patience: 9\n",
            "Epoch: 42 | train_loss: 0.00062, val_loss: 0.00147, lr: 7.75E-06, _patience: 10\n",
            "Epoch: 43 | train_loss: 0.00061, val_loss: 0.00150, lr: 7.75E-06, _patience: 9\n",
            "Epoch: 44 | train_loss: 0.00063, val_loss: 0.00146, lr: 7.75E-06, _patience: 10\n",
            "Epoch: 45 | train_loss: 0.00060, val_loss: 0.00148, lr: 7.75E-06, _patience: 9\n",
            "Epoch: 46 | train_loss: 0.00060, val_loss: 0.00149, lr: 7.75E-06, _patience: 8\n",
            "Epoch: 47 | train_loss: 0.00059, val_loss: 0.00148, lr: 7.75E-06, _patience: 7\n",
            "Epoch: 48 | train_loss: 0.00058, val_loss: 0.00149, lr: 7.75E-06, _patience: 6\n",
            "Epoch: 49 | train_loss: 0.00059, val_loss: 0.00148, lr: 7.75E-06, _patience: 5\n",
            "Epoch: 50 | train_loss: 0.00059, val_loss: 0.00150, lr: 7.75E-07, _patience: 4\n",
            "Epoch: 51 | train_loss: 0.00058, val_loss: 0.00150, lr: 7.75E-07, _patience: 3\n",
            "Epoch: 52 | train_loss: 0.00058, val_loss: 0.00149, lr: 7.75E-07, _patience: 2\n",
            "Epoch: 53 | train_loss: 0.00059, val_loss: 0.00149, lr: 7.75E-07, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:26:16,005]\u001b[0m Trial 1 finished with value: 0.6700979721048231 and parameters: {'embedding_dim': 489, 'num_filters': 454, 'hidden_dim': 347, 'dropout_p': 0.7225605841843792, 'lr': 7.750844913180659e-05}. Best is trial 1 with value: 0.6700979721048231.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00471, val_loss: 0.00338, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00356, val_loss: 0.00278, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00306, val_loss: 0.00260, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00282, val_loss: 0.00252, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00273, val_loss: 0.00242, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00255, val_loss: 0.00234, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00243, val_loss: 0.00224, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00228, val_loss: 0.00215, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00216, val_loss: 0.00208, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00205, val_loss: 0.00198, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00193, val_loss: 0.00192, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00181, val_loss: 0.00185, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00173, val_loss: 0.00179, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00161, val_loss: 0.00175, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00155, val_loss: 0.00171, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00148, val_loss: 0.00167, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00141, val_loss: 0.00163, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00132, val_loss: 0.00162, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00126, val_loss: 0.00160, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00121, val_loss: 0.00157, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00115, val_loss: 0.00156, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00112, val_loss: 0.00154, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00105, val_loss: 0.00153, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00099, val_loss: 0.00149, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00097, val_loss: 0.00150, lr: 6.66E-05, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00088, val_loss: 0.00150, lr: 6.66E-05, _patience: 8\n",
            "Epoch: 27 | train_loss: 0.00088, val_loss: 0.00149, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00083, val_loss: 0.00149, lr: 6.66E-05, _patience: 9\n",
            "Epoch: 29 | train_loss: 0.00081, val_loss: 0.00148, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00074, val_loss: 0.00147, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00072, val_loss: 0.00148, lr: 6.66E-05, _patience: 9\n",
            "Epoch: 32 | train_loss: 0.00069, val_loss: 0.00153, lr: 6.66E-05, _patience: 8\n",
            "Epoch: 33 | train_loss: 0.00066, val_loss: 0.00151, lr: 6.66E-05, _patience: 7\n",
            "Epoch: 34 | train_loss: 0.00064, val_loss: 0.00149, lr: 6.66E-05, _patience: 6\n",
            "Epoch: 35 | train_loss: 0.00059, val_loss: 0.00149, lr: 6.66E-05, _patience: 5\n",
            "Epoch: 36 | train_loss: 0.00056, val_loss: 0.00146, lr: 6.66E-05, _patience: 10\n",
            "Epoch: 37 | train_loss: 0.00054, val_loss: 0.00153, lr: 6.66E-05, _patience: 9\n",
            "Epoch: 38 | train_loss: 0.00052, val_loss: 0.00154, lr: 6.66E-05, _patience: 8\n",
            "Epoch: 39 | train_loss: 0.00051, val_loss: 0.00150, lr: 6.66E-05, _patience: 7\n",
            "Epoch: 40 | train_loss: 0.00050, val_loss: 0.00149, lr: 6.66E-05, _patience: 6\n",
            "Epoch: 41 | train_loss: 0.00048, val_loss: 0.00148, lr: 6.66E-05, _patience: 5\n",
            "Epoch: 42 | train_loss: 0.00045, val_loss: 0.00148, lr: 6.66E-06, _patience: 4\n",
            "Epoch: 43 | train_loss: 0.00043, val_loss: 0.00147, lr: 6.66E-06, _patience: 3\n",
            "Epoch: 44 | train_loss: 0.00041, val_loss: 0.00146, lr: 6.66E-06, _patience: 2\n",
            "Epoch: 45 | train_loss: 0.00041, val_loss: 0.00146, lr: 6.66E-06, _patience: 10\n",
            "Epoch: 46 | train_loss: 0.00039, val_loss: 0.00146, lr: 6.66E-06, _patience: 9\n",
            "Epoch: 47 | train_loss: 0.00040, val_loss: 0.00145, lr: 6.66E-06, _patience: 10\n",
            "Epoch: 48 | train_loss: 0.00039, val_loss: 0.00146, lr: 6.66E-06, _patience: 9\n",
            "Epoch: 49 | train_loss: 0.00039, val_loss: 0.00146, lr: 6.66E-06, _patience: 8\n",
            "Epoch: 50 | train_loss: 0.00039, val_loss: 0.00146, lr: 6.66E-06, _patience: 7\n",
            "Epoch: 51 | train_loss: 0.00038, val_loss: 0.00146, lr: 6.66E-06, _patience: 6\n",
            "Epoch: 52 | train_loss: 0.00038, val_loss: 0.00147, lr: 6.66E-06, _patience: 5\n",
            "Epoch: 53 | train_loss: 0.00038, val_loss: 0.00146, lr: 6.66E-07, _patience: 4\n",
            "Epoch: 54 | train_loss: 0.00038, val_loss: 0.00146, lr: 6.66E-07, _patience: 3\n",
            "Epoch: 55 | train_loss: 0.00038, val_loss: 0.00146, lr: 6.66E-07, _patience: 2\n",
            "Epoch: 56 | train_loss: 0.00038, val_loss: 0.00146, lr: 6.66E-07, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:28:51,920]\u001b[0m Trial 2 finished with value: 0.6690563213214246 and parameters: {'embedding_dim': 433, 'num_filters': 315, 'hidden_dim': 480, 'dropout_p': 0.563389016090152, 'lr': 6.663875446941576e-05}. Best is trial 1 with value: 0.6700979721048231.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00497, val_loss: 0.00274, lr: 4.93E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00296, val_loss: 0.00236, lr: 4.93E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00224, val_loss: 0.00194, lr: 4.93E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00176, val_loss: 0.00176, lr: 4.93E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00142, val_loss: 0.00164, lr: 4.93E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00110, val_loss: 0.00157, lr: 4.93E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00085, val_loss: 0.00158, lr: 4.93E-04, _patience: 9\n",
            "Epoch: 8 | train_loss: 0.00070, val_loss: 0.00163, lr: 4.93E-04, _patience: 8\n",
            "Epoch: 9 | train_loss: 0.00055, val_loss: 0.00164, lr: 4.93E-04, _patience: 7\n",
            "Epoch: 10 | train_loss: 0.00042, val_loss: 0.00160, lr: 4.93E-04, _patience: 6\n",
            "Epoch: 11 | train_loss: 0.00036, val_loss: 0.00171, lr: 4.93E-04, _patience: 5\n",
            "Epoch: 12 | train_loss: 0.00031, val_loss: 0.00170, lr: 4.93E-05, _patience: 4\n",
            "Epoch: 13 | train_loss: 0.00026, val_loss: 0.00157, lr: 4.93E-05, _patience: 3\n",
            "Epoch: 14 | train_loss: 0.00020, val_loss: 0.00162, lr: 4.93E-05, _patience: 2\n",
            "Epoch: 15 | train_loss: 0.00019, val_loss: 0.00160, lr: 4.93E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:29:24,304]\u001b[0m Trial 3 finished with value: 0.7006070644714198 and parameters: {'embedding_dim': 492, 'num_filters': 198, 'hidden_dim': 385, 'dropout_p': 0.3326167065482074, 'lr': 0.0004932086554846984}. Best is trial 3 with value: 0.7006070644714198.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00537, val_loss: 0.00364, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00404, val_loss: 0.00271, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00349, val_loss: 0.00264, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00322, val_loss: 0.00257, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00305, val_loss: 0.00250, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00291, val_loss: 0.00243, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00274, val_loss: 0.00231, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00253, val_loss: 0.00223, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00240, val_loss: 0.00212, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00227, val_loss: 0.00204, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00215, val_loss: 0.00198, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00200, val_loss: 0.00191, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00193, val_loss: 0.00183, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00181, val_loss: 0.00181, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00170, val_loss: 0.00178, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00165, val_loss: 0.00172, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00156, val_loss: 0.00167, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00151, val_loss: 0.00167, lr: 2.12E-04, _patience: 9\n",
            "Epoch: 19 | train_loss: 0.00143, val_loss: 0.00165, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00137, val_loss: 0.00171, lr: 2.12E-04, _patience: 9\n",
            "Epoch: 21 | train_loss: 0.00134, val_loss: 0.00160, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00124, val_loss: 0.00159, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00118, val_loss: 0.00165, lr: 2.12E-04, _patience: 9\n",
            "Epoch: 24 | train_loss: 0.00115, val_loss: 0.00151, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00105, val_loss: 0.00153, lr: 2.12E-04, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00105, val_loss: 0.00163, lr: 2.12E-04, _patience: 8\n",
            "Epoch: 27 | train_loss: 0.00099, val_loss: 0.00159, lr: 2.12E-04, _patience: 7\n",
            "Epoch: 28 | train_loss: 0.00094, val_loss: 0.00157, lr: 2.12E-04, _patience: 6\n",
            "Epoch: 29 | train_loss: 0.00090, val_loss: 0.00158, lr: 2.12E-04, _patience: 5\n",
            "Epoch: 30 | train_loss: 0.00087, val_loss: 0.00150, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00082, val_loss: 0.00152, lr: 2.12E-04, _patience: 9\n",
            "Epoch: 32 | train_loss: 0.00082, val_loss: 0.00160, lr: 2.12E-04, _patience: 8\n",
            "Epoch: 33 | train_loss: 0.00077, val_loss: 0.00166, lr: 2.12E-04, _patience: 7\n",
            "Epoch: 34 | train_loss: 0.00072, val_loss: 0.00148, lr: 2.12E-04, _patience: 10\n",
            "Epoch: 35 | train_loss: 0.00070, val_loss: 0.00161, lr: 2.12E-04, _patience: 9\n",
            "Epoch: 36 | train_loss: 0.00065, val_loss: 0.00157, lr: 2.12E-04, _patience: 8\n",
            "Epoch: 37 | train_loss: 0.00066, val_loss: 0.00168, lr: 2.12E-04, _patience: 7\n",
            "Epoch: 38 | train_loss: 0.00062, val_loss: 0.00169, lr: 2.12E-04, _patience: 6\n",
            "Epoch: 39 | train_loss: 0.00061, val_loss: 0.00157, lr: 2.12E-04, _patience: 5\n",
            "Epoch: 40 | train_loss: 0.00058, val_loss: 0.00153, lr: 2.12E-05, _patience: 4\n",
            "Epoch: 41 | train_loss: 0.00055, val_loss: 0.00168, lr: 2.12E-05, _patience: 3\n",
            "Epoch: 42 | train_loss: 0.00053, val_loss: 0.00151, lr: 2.12E-05, _patience: 2\n",
            "Epoch: 43 | train_loss: 0.00050, val_loss: 0.00156, lr: 2.12E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:30:04,007]\u001b[0m Trial 4 finished with value: 0.6604618456572443 and parameters: {'embedding_dim': 160, 'num_filters': 209, 'hidden_dim': 293, 'dropout_p': 0.7061580868550322, 'lr': 0.00021193970336840957}. Best is trial 3 with value: 0.7006070644714198.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00558, val_loss: 0.00278, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00330, val_loss: 0.00251, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00253, val_loss: 0.00205, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00200, val_loss: 0.00180, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00166, val_loss: 0.00168, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00136, val_loss: 0.00159, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00112, val_loss: 0.00153, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00093, val_loss: 0.00151, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00075, val_loss: 0.00161, lr: 3.48E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00060, val_loss: 0.00160, lr: 3.48E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00052, val_loss: 0.00162, lr: 3.48E-04, _patience: 7\n",
            "Epoch: 12 | train_loss: 0.00045, val_loss: 0.00157, lr: 3.48E-04, _patience: 6\n",
            "Epoch: 13 | train_loss: 0.00037, val_loss: 0.00165, lr: 3.48E-04, _patience: 5\n",
            "Epoch: 14 | train_loss: 0.00034, val_loss: 0.00174, lr: 3.48E-05, _patience: 4\n",
            "Epoch: 15 | train_loss: 0.00029, val_loss: 0.00153, lr: 3.48E-05, _patience: 3\n",
            "Epoch: 16 | train_loss: 0.00023, val_loss: 0.00157, lr: 3.48E-05, _patience: 2\n",
            "Epoch: 17 | train_loss: 0.00022, val_loss: 0.00159, lr: 3.48E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:31:02,512]\u001b[0m Trial 5 finished with value: 0.6762533306367564 and parameters: {'embedding_dim': 510, 'num_filters': 332, 'hidden_dim': 452, 'dropout_p': 0.493073445251808, 'lr': 0.0003482384669259982}. Best is trial 3 with value: 0.7006070644714198.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00523, val_loss: 0.00290, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00345, val_loss: 0.00287, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00321, val_loss: 0.00263, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00303, val_loss: 0.00255, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00289, val_loss: 0.00249, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00278, val_loss: 0.00242, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00266, val_loss: 0.00235, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00255, val_loss: 0.00228, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00242, val_loss: 0.00222, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00236, val_loss: 0.00216, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00226, val_loss: 0.00208, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00214, val_loss: 0.00203, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00205, val_loss: 0.00198, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00201, val_loss: 0.00193, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00188, val_loss: 0.00189, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00181, val_loss: 0.00185, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00177, val_loss: 0.00181, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00170, val_loss: 0.00178, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00160, val_loss: 0.00176, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00157, val_loss: 0.00172, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00152, val_loss: 0.00170, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00144, val_loss: 0.00169, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00137, val_loss: 0.00167, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00137, val_loss: 0.00163, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00132, val_loss: 0.00162, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00126, val_loss: 0.00161, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00124, val_loss: 0.00161, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00116, val_loss: 0.00159, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00115, val_loss: 0.00157, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00111, val_loss: 0.00157, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00108, val_loss: 0.00157, lr: 5.64E-05, _patience: 9\n",
            "Epoch: 32 | train_loss: 0.00106, val_loss: 0.00156, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00101, val_loss: 0.00155, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00097, val_loss: 0.00155, lr: 5.64E-05, _patience: 9\n",
            "Epoch: 35 | train_loss: 0.00093, val_loss: 0.00155, lr: 5.64E-05, _patience: 8\n",
            "Epoch: 36 | train_loss: 0.00091, val_loss: 0.00156, lr: 5.64E-05, _patience: 7\n",
            "Epoch: 37 | train_loss: 0.00090, val_loss: 0.00152, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 38 | train_loss: 0.00086, val_loss: 0.00150, lr: 5.64E-05, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00084, val_loss: 0.00153, lr: 5.64E-05, _patience: 9\n",
            "Epoch: 40 | train_loss: 0.00080, val_loss: 0.00153, lr: 5.64E-05, _patience: 8\n",
            "Epoch: 41 | train_loss: 0.00078, val_loss: 0.00152, lr: 5.64E-05, _patience: 7\n",
            "Epoch: 42 | train_loss: 0.00077, val_loss: 0.00153, lr: 5.64E-05, _patience: 6\n",
            "Epoch: 43 | train_loss: 0.00074, val_loss: 0.00152, lr: 5.64E-05, _patience: 5\n",
            "Epoch: 44 | train_loss: 0.00073, val_loss: 0.00151, lr: 5.64E-06, _patience: 4\n",
            "Epoch: 45 | train_loss: 0.00069, val_loss: 0.00150, lr: 5.64E-06, _patience: 10\n",
            "Epoch: 46 | train_loss: 0.00069, val_loss: 0.00148, lr: 5.64E-06, _patience: 10\n",
            "Epoch: 47 | train_loss: 0.00067, val_loss: 0.00148, lr: 5.64E-06, _patience: 9\n",
            "Epoch: 48 | train_loss: 0.00066, val_loss: 0.00149, lr: 5.64E-06, _patience: 8\n",
            "Epoch: 49 | train_loss: 0.00067, val_loss: 0.00148, lr: 5.64E-06, _patience: 10\n",
            "Epoch: 50 | train_loss: 0.00065, val_loss: 0.00149, lr: 5.64E-06, _patience: 9\n",
            "Epoch: 51 | train_loss: 0.00066, val_loss: 0.00148, lr: 5.64E-06, _patience: 10\n",
            "Epoch: 52 | train_loss: 0.00067, val_loss: 0.00149, lr: 5.64E-06, _patience: 9\n",
            "Epoch: 53 | train_loss: 0.00066, val_loss: 0.00148, lr: 5.64E-06, _patience: 10\n",
            "Epoch: 54 | train_loss: 0.00066, val_loss: 0.00148, lr: 5.64E-06, _patience: 10\n",
            "Epoch: 55 | train_loss: 0.00064, val_loss: 0.00148, lr: 5.64E-06, _patience: 9\n",
            "Epoch: 56 | train_loss: 0.00064, val_loss: 0.00148, lr: 5.64E-06, _patience: 8\n",
            "Epoch: 57 | train_loss: 0.00065, val_loss: 0.00148, lr: 5.64E-06, _patience: 7\n",
            "Epoch: 58 | train_loss: 0.00064, val_loss: 0.00148, lr: 5.64E-06, _patience: 10\n",
            "Epoch: 59 | train_loss: 0.00064, val_loss: 0.00149, lr: 5.64E-06, _patience: 9\n",
            "Epoch: 60 | train_loss: 0.00062, val_loss: 0.00149, lr: 5.64E-06, _patience: 8\n",
            "Epoch: 61 | train_loss: 0.00063, val_loss: 0.00148, lr: 5.64E-06, _patience: 7\n",
            "Epoch: 62 | train_loss: 0.00064, val_loss: 0.00148, lr: 5.64E-06, _patience: 6\n",
            "Epoch: 63 | train_loss: 0.00063, val_loss: 0.00149, lr: 5.64E-06, _patience: 5\n",
            "Epoch: 64 | train_loss: 0.00063, val_loss: 0.00149, lr: 5.64E-07, _patience: 4\n",
            "Epoch: 65 | train_loss: 0.00063, val_loss: 0.00149, lr: 5.64E-07, _patience: 3\n",
            "Epoch: 66 | train_loss: 0.00062, val_loss: 0.00149, lr: 5.64E-07, _patience: 2\n",
            "Epoch: 67 | train_loss: 0.00062, val_loss: 0.00149, lr: 5.64E-07, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:33:48,429]\u001b[0m Trial 6 finished with value: 0.64163636445738 and parameters: {'embedding_dim': 364, 'num_filters': 350, 'hidden_dim': 131, 'dropout_p': 0.35375492179098506, 'lr': 5.643457276835367e-05}. Best is trial 3 with value: 0.7006070644714198.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00565, val_loss: 0.00349, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00395, val_loss: 0.00273, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00328, val_loss: 0.00266, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00307, val_loss: 0.00256, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00286, val_loss: 0.00244, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00269, val_loss: 0.00232, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00248, val_loss: 0.00216, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00224, val_loss: 0.00204, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00204, val_loss: 0.00192, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00191, val_loss: 0.00182, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00178, val_loss: 0.00175, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00166, val_loss: 0.00169, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00152, val_loss: 0.00166, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00140, val_loss: 0.00161, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00132, val_loss: 0.00161, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00121, val_loss: 0.00158, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00114, val_loss: 0.00159, lr: 4.02E-04, _patience: 9\n",
            "Epoch: 18 | train_loss: 0.00103, val_loss: 0.00153, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00098, val_loss: 0.00154, lr: 4.02E-04, _patience: 9\n",
            "Epoch: 20 | train_loss: 0.00089, val_loss: 0.00156, lr: 4.02E-04, _patience: 8\n",
            "Epoch: 21 | train_loss: 0.00083, val_loss: 0.00152, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00076, val_loss: 0.00149, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00073, val_loss: 0.00170, lr: 4.02E-04, _patience: 9\n",
            "Epoch: 24 | train_loss: 0.00071, val_loss: 0.00163, lr: 4.02E-04, _patience: 8\n",
            "Epoch: 25 | train_loss: 0.00064, val_loss: 0.00169, lr: 4.02E-04, _patience: 7\n",
            "Epoch: 26 | train_loss: 0.00061, val_loss: 0.00146, lr: 4.02E-04, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00059, val_loss: 0.00166, lr: 4.02E-04, _patience: 9\n",
            "Epoch: 28 | train_loss: 0.00058, val_loss: 0.00188, lr: 4.02E-04, _patience: 8\n",
            "Epoch: 29 | train_loss: 0.00056, val_loss: 0.00180, lr: 4.02E-04, _patience: 7\n",
            "Epoch: 30 | train_loss: 0.00053, val_loss: 0.00155, lr: 4.02E-04, _patience: 6\n",
            "Epoch: 31 | train_loss: 0.00049, val_loss: 0.00161, lr: 4.02E-04, _patience: 5\n",
            "Epoch: 32 | train_loss: 0.00046, val_loss: 0.00200, lr: 4.02E-05, _patience: 4\n",
            "Epoch: 33 | train_loss: 0.00046, val_loss: 0.00154, lr: 4.02E-05, _patience: 3\n",
            "Epoch: 34 | train_loss: 0.00037, val_loss: 0.00165, lr: 4.02E-05, _patience: 2\n",
            "Epoch: 35 | train_loss: 0.00037, val_loss: 0.00164, lr: 4.02E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:34:10,730]\u001b[0m Trial 7 finished with value: 0.6656754517992355 and parameters: {'embedding_dim': 135, 'num_filters': 152, 'hidden_dim': 468, 'dropout_p': 0.776901143629122, 'lr': 0.0004017664913919758}. Best is trial 3 with value: 0.7006070644714198.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00798, val_loss: 0.00338, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00472, val_loss: 0.00267, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00386, val_loss: 0.00255, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00342, val_loss: 0.00241, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00306, val_loss: 0.00229, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00289, val_loss: 0.00217, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00265, val_loss: 0.00204, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00248, val_loss: 0.00201, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00234, val_loss: 0.00189, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00215, val_loss: 0.00183, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00198, val_loss: 0.00183, lr: 2.61E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00184, val_loss: 0.00170, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00176, val_loss: 0.00169, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00161, val_loss: 0.00176, lr: 2.61E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00152, val_loss: 0.00167, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00144, val_loss: 0.00162, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00134, val_loss: 0.00158, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00129, val_loss: 0.00171, lr: 2.61E-04, _patience: 9\n",
            "Epoch: 19 | train_loss: 0.00121, val_loss: 0.00163, lr: 2.61E-04, _patience: 8\n",
            "Epoch: 20 | train_loss: 0.00120, val_loss: 0.00150, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00112, val_loss: 0.00154, lr: 2.61E-04, _patience: 9\n",
            "Epoch: 22 | train_loss: 0.00103, val_loss: 0.00178, lr: 2.61E-04, _patience: 8\n",
            "Epoch: 23 | train_loss: 0.00102, val_loss: 0.00195, lr: 2.61E-04, _patience: 7\n",
            "Epoch: 24 | train_loss: 0.00101, val_loss: 0.00192, lr: 2.61E-04, _patience: 6\n",
            "Epoch: 25 | train_loss: 0.00105, val_loss: 0.00146, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00109, val_loss: 0.00163, lr: 2.61E-04, _patience: 9\n",
            "Epoch: 27 | train_loss: 0.00096, val_loss: 0.00196, lr: 2.61E-04, _patience: 8\n",
            "Epoch: 28 | train_loss: 0.00083, val_loss: 0.00172, lr: 2.61E-04, _patience: 7\n",
            "Epoch: 29 | train_loss: 0.00078, val_loss: 0.00160, lr: 2.61E-04, _patience: 6\n",
            "Epoch: 30 | train_loss: 0.00072, val_loss: 0.00181, lr: 2.61E-04, _patience: 5\n",
            "Epoch: 31 | train_loss: 0.00069, val_loss: 0.00190, lr: 2.61E-05, _patience: 4\n",
            "Epoch: 32 | train_loss: 0.00070, val_loss: 0.00155, lr: 2.61E-05, _patience: 3\n",
            "Epoch: 33 | train_loss: 0.00059, val_loss: 0.00169, lr: 2.61E-05, _patience: 2\n",
            "Epoch: 34 | train_loss: 0.00057, val_loss: 0.00161, lr: 2.61E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:35:38,746]\u001b[0m Trial 8 finished with value: 0.6645311189425309 and parameters: {'embedding_dim': 258, 'num_filters': 502, 'hidden_dim': 273, 'dropout_p': 0.7895894577967083, 'lr': 0.0002610158435942419}. Best is trial 3 with value: 0.7006070644714198.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00627, val_loss: 0.00331, lr: 3.07E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00399, val_loss: 0.00256, lr: 3.07E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00325, val_loss: 0.00235, lr: 3.07E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00278, val_loss: 0.00220, lr: 3.07E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00246, val_loss: 0.00197, lr: 3.07E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00219, val_loss: 0.00193, lr: 3.07E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00196, val_loss: 0.00177, lr: 3.07E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00178, val_loss: 0.00179, lr: 3.07E-04, _patience: 9\n",
            "Epoch: 9 | train_loss: 0.00160, val_loss: 0.00169, lr: 3.07E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00149, val_loss: 0.00165, lr: 3.07E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00133, val_loss: 0.00171, lr: 3.07E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00125, val_loss: 0.00169, lr: 3.07E-04, _patience: 8\n",
            "Epoch: 13 | train_loss: 0.00110, val_loss: 0.00159, lr: 3.07E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00100, val_loss: 0.00155, lr: 3.07E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00093, val_loss: 0.00165, lr: 3.07E-04, _patience: 9\n",
            "Epoch: 16 | train_loss: 0.00087, val_loss: 0.00154, lr: 3.07E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00078, val_loss: 0.00155, lr: 3.07E-04, _patience: 9\n",
            "Epoch: 18 | train_loss: 0.00073, val_loss: 0.00186, lr: 3.07E-04, _patience: 8\n",
            "Epoch: 19 | train_loss: 0.00073, val_loss: 0.00182, lr: 3.07E-04, _patience: 7\n",
            "Epoch: 20 | train_loss: 0.00069, val_loss: 0.00180, lr: 3.07E-04, _patience: 6\n",
            "Epoch: 21 | train_loss: 0.00064, val_loss: 0.00180, lr: 3.07E-04, _patience: 5\n",
            "Epoch: 22 | train_loss: 0.00062, val_loss: 0.00189, lr: 3.07E-05, _patience: 4\n",
            "Epoch: 23 | train_loss: 0.00056, val_loss: 0.00163, lr: 3.07E-05, _patience: 3\n",
            "Epoch: 24 | train_loss: 0.00049, val_loss: 0.00164, lr: 3.07E-05, _patience: 2\n",
            "Epoch: 25 | train_loss: 0.00045, val_loss: 0.00163, lr: 3.07E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:36:47,677]\u001b[0m Trial 9 finished with value: 0.66978151495889 and parameters: {'embedding_dim': 454, 'num_filters': 280, 'hidden_dim': 201, 'dropout_p': 0.6571828583575179, 'lr': 0.00030717147778186286}. Best is trial 3 with value: 0.7006070644714198.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00451, val_loss: 0.00327, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00318, val_loss: 0.00265, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00276, val_loss: 0.00254, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00260, val_loss: 0.00241, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00241, val_loss: 0.00226, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00220, val_loss: 0.00212, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00203, val_loss: 0.00200, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00184, val_loss: 0.00190, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00170, val_loss: 0.00180, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00157, val_loss: 0.00172, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00144, val_loss: 0.00168, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00136, val_loss: 0.00163, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00126, val_loss: 0.00158, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00114, val_loss: 0.00156, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00110, val_loss: 0.00152, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00099, val_loss: 0.00152, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00092, val_loss: 0.00152, lr: 1.35E-04, _patience: 9\n",
            "Epoch: 18 | train_loss: 0.00087, val_loss: 0.00151, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00082, val_loss: 0.00147, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00073, val_loss: 0.00148, lr: 1.35E-04, _patience: 9\n",
            "Epoch: 21 | train_loss: 0.00068, val_loss: 0.00150, lr: 1.35E-04, _patience: 8\n",
            "Epoch: 22 | train_loss: 0.00065, val_loss: 0.00147, lr: 1.35E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00059, val_loss: 0.00149, lr: 1.35E-04, _patience: 9\n",
            "Epoch: 24 | train_loss: 0.00055, val_loss: 0.00148, lr: 1.35E-04, _patience: 8\n",
            "Epoch: 25 | train_loss: 0.00051, val_loss: 0.00149, lr: 1.35E-05, _patience: 7\n",
            "Epoch: 26 | train_loss: 0.00048, val_loss: 0.00143, lr: 1.35E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00046, val_loss: 0.00142, lr: 1.35E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00045, val_loss: 0.00144, lr: 1.35E-05, _patience: 9\n",
            "Epoch: 29 | train_loss: 0.00044, val_loss: 0.00144, lr: 1.35E-05, _patience: 8\n",
            "Epoch: 30 | train_loss: 0.00044, val_loss: 0.00144, lr: 1.35E-05, _patience: 7\n",
            "Epoch: 31 | train_loss: 0.00044, val_loss: 0.00144, lr: 1.35E-05, _patience: 6\n",
            "Epoch: 32 | train_loss: 0.00043, val_loss: 0.00143, lr: 1.35E-05, _patience: 5\n",
            "Epoch: 33 | train_loss: 0.00042, val_loss: 0.00144, lr: 1.35E-06, _patience: 4\n",
            "Epoch: 34 | train_loss: 0.00043, val_loss: 0.00143, lr: 1.35E-06, _patience: 3\n",
            "Epoch: 35 | train_loss: 0.00043, val_loss: 0.00143, lr: 1.35E-06, _patience: 2\n",
            "Epoch: 36 | train_loss: 0.00042, val_loss: 0.00143, lr: 1.35E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:37:36,799]\u001b[0m Trial 10 finished with value: 0.667306498245895 and parameters: {'embedding_dim': 371, 'num_filters': 142, 'hidden_dim': 377, 'dropout_p': 0.3096948773038894, 'lr': 0.0001345063000806952}. Best is trial 3 with value: 0.7006070644714198.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00629, val_loss: 0.00278, lr: 4.80E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00300, val_loss: 0.00233, lr: 4.80E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00227, val_loss: 0.00193, lr: 4.80E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00180, val_loss: 0.00181, lr: 4.80E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00141, val_loss: 0.00174, lr: 4.80E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00109, val_loss: 0.00164, lr: 4.80E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00084, val_loss: 0.00174, lr: 4.80E-04, _patience: 9\n",
            "Epoch: 8 | train_loss: 0.00067, val_loss: 0.00164, lr: 4.80E-04, _patience: 8\n",
            "Epoch: 9 | train_loss: 0.00050, val_loss: 0.00173, lr: 4.80E-04, _patience: 7\n",
            "Epoch: 10 | train_loss: 0.00041, val_loss: 0.00164, lr: 4.80E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00038, val_loss: 0.00172, lr: 4.80E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00031, val_loss: 0.00183, lr: 4.80E-04, _patience: 8\n",
            "Epoch: 13 | train_loss: 0.00027, val_loss: 0.00178, lr: 4.80E-04, _patience: 7\n",
            "Epoch: 14 | train_loss: 0.00023, val_loss: 0.00169, lr: 4.80E-04, _patience: 6\n",
            "Epoch: 15 | train_loss: 0.00020, val_loss: 0.00204, lr: 4.80E-04, _patience: 5\n",
            "Epoch: 16 | train_loss: 0.00018, val_loss: 0.00199, lr: 4.80E-05, _patience: 4\n",
            "Epoch: 17 | train_loss: 0.00016, val_loss: 0.00182, lr: 4.80E-05, _patience: 3\n",
            "Epoch: 18 | train_loss: 0.00011, val_loss: 0.00183, lr: 4.80E-05, _patience: 2\n",
            "Epoch: 19 | train_loss: 0.00009, val_loss: 0.00185, lr: 4.80E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:38:49,496]\u001b[0m Trial 11 finished with value: 0.7051560266298316 and parameters: {'embedding_dim': 492, 'num_filters': 397, 'hidden_dim': 420, 'dropout_p': 0.415083093686176, 'lr': 0.000479937827664147}. Best is trial 11 with value: 0.7051560266298316.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00685, val_loss: 0.00295, lr: 4.77E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00322, val_loss: 0.00244, lr: 4.77E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00238, val_loss: 0.00198, lr: 4.77E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00187, val_loss: 0.00176, lr: 4.77E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00148, val_loss: 0.00162, lr: 4.77E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00115, val_loss: 0.00155, lr: 4.77E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00087, val_loss: 0.00156, lr: 4.77E-04, _patience: 9\n",
            "Epoch: 8 | train_loss: 0.00069, val_loss: 0.00161, lr: 4.77E-04, _patience: 8\n",
            "Epoch: 9 | train_loss: 0.00055, val_loss: 0.00161, lr: 4.77E-04, _patience: 7\n",
            "Epoch: 10 | train_loss: 0.00043, val_loss: 0.00167, lr: 4.77E-04, _patience: 6\n",
            "Epoch: 11 | train_loss: 0.00036, val_loss: 0.00187, lr: 4.77E-04, _patience: 5\n",
            "Epoch: 12 | train_loss: 0.00032, val_loss: 0.00183, lr: 4.77E-05, _patience: 4\n",
            "Epoch: 13 | train_loss: 0.00026, val_loss: 0.00160, lr: 4.77E-05, _patience: 3\n",
            "Epoch: 14 | train_loss: 0.00020, val_loss: 0.00165, lr: 4.77E-05, _patience: 2\n",
            "Epoch: 15 | train_loss: 0.00019, val_loss: 0.00165, lr: 4.77E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:39:51,556]\u001b[0m Trial 12 finished with value: 0.6977403242123549 and parameters: {'embedding_dim': 511, 'num_filters': 414, 'hidden_dim': 411, 'dropout_p': 0.3991779992616886, 'lr': 0.0004773332201413353}. Best is trial 11 with value: 0.7051560266298316.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00514, val_loss: 0.00280, lr: 4.78E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00316, val_loss: 0.00245, lr: 4.78E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00242, val_loss: 0.00204, lr: 4.78E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00191, val_loss: 0.00182, lr: 4.78E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00155, val_loss: 0.00173, lr: 4.78E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00129, val_loss: 0.00163, lr: 4.78E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00104, val_loss: 0.00157, lr: 4.78E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00083, val_loss: 0.00154, lr: 4.78E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00067, val_loss: 0.00159, lr: 4.78E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00057, val_loss: 0.00168, lr: 4.78E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00047, val_loss: 0.00182, lr: 4.78E-04, _patience: 7\n",
            "Epoch: 12 | train_loss: 0.00043, val_loss: 0.00171, lr: 4.78E-04, _patience: 6\n",
            "Epoch: 13 | train_loss: 0.00034, val_loss: 0.00172, lr: 4.78E-04, _patience: 5\n",
            "Epoch: 14 | train_loss: 0.00029, val_loss: 0.00204, lr: 4.78E-05, _patience: 4\n",
            "Epoch: 15 | train_loss: 0.00025, val_loss: 0.00164, lr: 4.78E-05, _patience: 3\n",
            "Epoch: 16 | train_loss: 0.00020, val_loss: 0.00165, lr: 4.78E-05, _patience: 2\n",
            "Epoch: 17 | train_loss: 0.00019, val_loss: 0.00165, lr: 4.78E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:40:24,613]\u001b[0m Trial 13 finished with value: 0.6791010151428308 and parameters: {'embedding_dim': 415, 'num_filters': 221, 'hidden_dim': 400, 'dropout_p': 0.41386450844400835, 'lr': 0.00047823584487243756}. Best is trial 11 with value: 0.7051560266298316.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00487, val_loss: 0.00325, lr: 2.15E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00321, val_loss: 0.00255, lr: 2.15E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00259, val_loss: 0.00232, lr: 2.15E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00227, val_loss: 0.00205, lr: 2.15E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00193, val_loss: 0.00189, lr: 2.15E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00168, val_loss: 0.00182, lr: 2.15E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00147, val_loss: 0.00170, lr: 2.15E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00130, val_loss: 0.00166, lr: 2.15E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00113, val_loss: 0.00168, lr: 2.15E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00101, val_loss: 0.00165, lr: 2.15E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00090, val_loss: 0.00164, lr: 2.15E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00080, val_loss: 0.00161, lr: 2.15E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00072, val_loss: 0.00158, lr: 2.15E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00063, val_loss: 0.00153, lr: 2.15E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00055, val_loss: 0.00147, lr: 2.15E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00046, val_loss: 0.00148, lr: 2.15E-04, _patience: 9\n",
            "Epoch: 17 | train_loss: 0.00043, val_loss: 0.00157, lr: 2.15E-04, _patience: 8\n",
            "Epoch: 18 | train_loss: 0.00039, val_loss: 0.00159, lr: 2.15E-04, _patience: 7\n",
            "Epoch: 19 | train_loss: 0.00036, val_loss: 0.00169, lr: 2.15E-04, _patience: 6\n",
            "Epoch: 20 | train_loss: 0.00033, val_loss: 0.00163, lr: 2.15E-04, _patience: 5\n",
            "Epoch: 21 | train_loss: 0.00030, val_loss: 0.00167, lr: 2.15E-05, _patience: 4\n",
            "Epoch: 22 | train_loss: 0.00026, val_loss: 0.00154, lr: 2.15E-05, _patience: 3\n",
            "Epoch: 23 | train_loss: 0.00023, val_loss: 0.00154, lr: 2.15E-05, _patience: 2\n",
            "Epoch: 24 | train_loss: 0.00022, val_loss: 0.00154, lr: 2.15E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:41:22,568]\u001b[0m Trial 14 finished with value: 0.674090385172307 and parameters: {'embedding_dim': 296, 'num_filters': 395, 'hidden_dim': 338, 'dropout_p': 0.30679127370480475, 'lr': 0.0002150334075930382}. Best is trial 11 with value: 0.7051560266298316.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00738, val_loss: 0.00292, lr: 4.86E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00320, val_loss: 0.00244, lr: 4.86E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00243, val_loss: 0.00194, lr: 4.86E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00189, val_loss: 0.00173, lr: 4.86E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00149, val_loss: 0.00163, lr: 4.86E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00118, val_loss: 0.00155, lr: 4.86E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00089, val_loss: 0.00154, lr: 4.86E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00068, val_loss: 0.00151, lr: 4.86E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00051, val_loss: 0.00158, lr: 4.86E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00039, val_loss: 0.00158, lr: 4.86E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00033, val_loss: 0.00157, lr: 4.86E-04, _patience: 7\n",
            "Epoch: 12 | train_loss: 0.00029, val_loss: 0.00168, lr: 4.86E-04, _patience: 6\n",
            "Epoch: 13 | train_loss: 0.00025, val_loss: 0.00201, lr: 4.86E-04, _patience: 5\n",
            "Epoch: 14 | train_loss: 0.00022, val_loss: 0.00183, lr: 4.86E-05, _patience: 4\n",
            "Epoch: 15 | train_loss: 0.00017, val_loss: 0.00176, lr: 4.86E-05, _patience: 3\n",
            "Epoch: 16 | train_loss: 0.00014, val_loss: 0.00175, lr: 4.86E-05, _patience: 2\n",
            "Epoch: 17 | train_loss: 0.00012, val_loss: 0.00174, lr: 4.86E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:42:38,023]\u001b[0m Trial 15 finished with value: 0.7081352359515858 and parameters: {'embedding_dim': 473, 'num_filters': 512, 'hidden_dim': 505, 'dropout_p': 0.4337075433076099, 'lr': 0.00048576973840205764}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00456, val_loss: 0.00343, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00326, val_loss: 0.00262, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00278, val_loss: 0.00249, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00250, val_loss: 0.00227, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00224, val_loss: 0.00214, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00202, val_loss: 0.00201, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00182, val_loss: 0.00190, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00170, val_loss: 0.00181, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00155, val_loss: 0.00173, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00145, val_loss: 0.00170, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00133, val_loss: 0.00163, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00121, val_loss: 0.00162, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00110, val_loss: 0.00160, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00100, val_loss: 0.00157, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00092, val_loss: 0.00155, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00084, val_loss: 0.00150, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00080, val_loss: 0.00158, lr: 1.04E-04, _patience: 9\n",
            "Epoch: 18 | train_loss: 0.00073, val_loss: 0.00149, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00067, val_loss: 0.00151, lr: 1.04E-04, _patience: 9\n",
            "Epoch: 20 | train_loss: 0.00062, val_loss: 0.00149, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00058, val_loss: 0.00146, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00051, val_loss: 0.00144, lr: 1.04E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00050, val_loss: 0.00147, lr: 1.04E-04, _patience: 9\n",
            "Epoch: 24 | train_loss: 0.00045, val_loss: 0.00147, lr: 1.04E-04, _patience: 8\n",
            "Epoch: 25 | train_loss: 0.00042, val_loss: 0.00150, lr: 1.04E-04, _patience: 7\n",
            "Epoch: 26 | train_loss: 0.00038, val_loss: 0.00150, lr: 1.04E-04, _patience: 6\n",
            "Epoch: 27 | train_loss: 0.00035, val_loss: 0.00152, lr: 1.04E-04, _patience: 5\n",
            "Epoch: 28 | train_loss: 0.00033, val_loss: 0.00156, lr: 1.04E-05, _patience: 4\n",
            "Epoch: 29 | train_loss: 0.00031, val_loss: 0.00149, lr: 1.04E-05, _patience: 3\n",
            "Epoch: 30 | train_loss: 0.00028, val_loss: 0.00147, lr: 1.04E-05, _patience: 2\n",
            "Epoch: 31 | train_loss: 0.00028, val_loss: 0.00148, lr: 1.04E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:44:26,782]\u001b[0m Trial 16 finished with value: 0.684089996546423 and parameters: {'embedding_dim': 366, 'num_filters': 509, 'hidden_dim': 509, 'dropout_p': 0.44575261184512505, 'lr': 0.0001039515268754127}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00539, val_loss: 0.00338, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00344, val_loss: 0.00249, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00274, val_loss: 0.00226, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00240, val_loss: 0.00202, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00207, val_loss: 0.00187, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00182, val_loss: 0.00179, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00160, val_loss: 0.00171, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00142, val_loss: 0.00161, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00122, val_loss: 0.00160, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00111, val_loss: 0.00156, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00099, val_loss: 0.00156, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00087, val_loss: 0.00153, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00076, val_loss: 0.00156, lr: 1.92E-04, _patience: 9\n",
            "Epoch: 14 | train_loss: 0.00070, val_loss: 0.00153, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00062, val_loss: 0.00157, lr: 1.92E-04, _patience: 9\n",
            "Epoch: 16 | train_loss: 0.00055, val_loss: 0.00157, lr: 1.92E-04, _patience: 8\n",
            "Epoch: 17 | train_loss: 0.00051, val_loss: 0.00158, lr: 1.92E-04, _patience: 7\n",
            "Epoch: 18 | train_loss: 0.00047, val_loss: 0.00158, lr: 1.92E-05, _patience: 6\n",
            "Epoch: 19 | train_loss: 0.00040, val_loss: 0.00151, lr: 1.92E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00037, val_loss: 0.00148, lr: 1.92E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00034, val_loss: 0.00149, lr: 1.92E-05, _patience: 9\n",
            "Epoch: 22 | train_loss: 0.00033, val_loss: 0.00150, lr: 1.92E-05, _patience: 8\n",
            "Epoch: 23 | train_loss: 0.00031, val_loss: 0.00150, lr: 1.92E-05, _patience: 7\n",
            "Epoch: 24 | train_loss: 0.00031, val_loss: 0.00148, lr: 1.92E-05, _patience: 6\n",
            "Epoch: 25 | train_loss: 0.00031, val_loss: 0.00149, lr: 1.92E-05, _patience: 5\n",
            "Epoch: 26 | train_loss: 0.00030, val_loss: 0.00149, lr: 1.92E-06, _patience: 4\n",
            "Epoch: 27 | train_loss: 0.00030, val_loss: 0.00149, lr: 1.92E-06, _patience: 3\n",
            "Epoch: 28 | train_loss: 0.00029, val_loss: 0.00149, lr: 1.92E-06, _patience: 2\n",
            "Epoch: 29 | train_loss: 0.00029, val_loss: 0.00149, lr: 1.92E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:46:13,191]\u001b[0m Trial 17 finished with value: 0.6799434219138696 and parameters: {'embedding_dim': 447, 'num_filters': 429, 'hidden_dim': 501, 'dropout_p': 0.5747323985837085, 'lr': 0.00019153228046257846}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00672, val_loss: 0.00302, lr: 3.71E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00340, val_loss: 0.00254, lr: 3.71E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00259, val_loss: 0.00209, lr: 3.71E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00204, val_loss: 0.00182, lr: 3.71E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00170, val_loss: 0.00172, lr: 3.71E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00143, val_loss: 0.00169, lr: 3.71E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00118, val_loss: 0.00158, lr: 3.71E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00094, val_loss: 0.00156, lr: 3.71E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00075, val_loss: 0.00157, lr: 3.71E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00060, val_loss: 0.00166, lr: 3.71E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00051, val_loss: 0.00169, lr: 3.71E-04, _patience: 7\n",
            "Epoch: 12 | train_loss: 0.00043, val_loss: 0.00168, lr: 3.71E-04, _patience: 6\n",
            "Epoch: 13 | train_loss: 0.00037, val_loss: 0.00178, lr: 3.71E-04, _patience: 5\n",
            "Epoch: 14 | train_loss: 0.00033, val_loss: 0.00171, lr: 3.71E-05, _patience: 4\n",
            "Epoch: 15 | train_loss: 0.00027, val_loss: 0.00162, lr: 3.71E-05, _patience: 3\n",
            "Epoch: 16 | train_loss: 0.00022, val_loss: 0.00161, lr: 3.71E-05, _patience: 2\n",
            "Epoch: 17 | train_loss: 0.00021, val_loss: 0.00161, lr: 3.71E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:47:15,871]\u001b[0m Trial 18 finished with value: 0.696878853681489 and parameters: {'embedding_dim': 395, 'num_filters': 471, 'hidden_dim': 442, 'dropout_p': 0.46056925992011705, 'lr': 0.0003706221648172483}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00524, val_loss: 0.00314, lr: 2.80E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00327, val_loss: 0.00252, lr: 2.80E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00259, val_loss: 0.00217, lr: 2.80E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00213, val_loss: 0.00189, lr: 2.80E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00176, val_loss: 0.00174, lr: 2.80E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00149, val_loss: 0.00167, lr: 2.80E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00127, val_loss: 0.00161, lr: 2.80E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00111, val_loss: 0.00157, lr: 2.80E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00093, val_loss: 0.00151, lr: 2.80E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00079, val_loss: 0.00158, lr: 2.80E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00067, val_loss: 0.00155, lr: 2.80E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00056, val_loss: 0.00160, lr: 2.80E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00051, val_loss: 0.00163, lr: 2.80E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00045, val_loss: 0.00161, lr: 2.80E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00037, val_loss: 0.00164, lr: 2.80E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00033, val_loss: 0.00149, lr: 2.80E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00027, val_loss: 0.00148, lr: 2.80E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00027, val_loss: 0.00148, lr: 2.80E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00026, val_loss: 0.00150, lr: 2.80E-05, _patience: 9\n",
            "Epoch: 20 | train_loss: 0.00025, val_loss: 0.00148, lr: 2.80E-05, _patience: 8\n",
            "Epoch: 21 | train_loss: 0.00025, val_loss: 0.00148, lr: 2.80E-05, _patience: 7\n",
            "Epoch: 22 | train_loss: 0.00024, val_loss: 0.00150, lr: 2.80E-05, _patience: 6\n",
            "Epoch: 23 | train_loss: 0.00024, val_loss: 0.00151, lr: 2.80E-05, _patience: 5\n",
            "Epoch: 24 | train_loss: 0.00023, val_loss: 0.00150, lr: 2.80E-06, _patience: 4\n",
            "Epoch: 25 | train_loss: 0.00023, val_loss: 0.00150, lr: 2.80E-06, _patience: 3\n",
            "Epoch: 26 | train_loss: 0.00024, val_loss: 0.00150, lr: 2.80E-06, _patience: 2\n",
            "Epoch: 27 | train_loss: 0.00023, val_loss: 0.00150, lr: 2.80E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:48:19,022]\u001b[0m Trial 19 finished with value: 0.663958896663722 and parameters: {'embedding_dim': 320, 'num_filters': 376, 'hidden_dim': 433, 'dropout_p': 0.3699893550575423, 'lr': 0.00027960910907676303}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00797, val_loss: 0.00299, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00351, val_loss: 0.00259, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00268, val_loss: 0.00212, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00212, val_loss: 0.00182, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00170, val_loss: 0.00173, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00142, val_loss: 0.00169, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00115, val_loss: 0.00160, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00090, val_loss: 0.00161, lr: 4.98E-04, _patience: 9\n",
            "Epoch: 9 | train_loss: 0.00077, val_loss: 0.00171, lr: 4.98E-04, _patience: 8\n",
            "Epoch: 10 | train_loss: 0.00062, val_loss: 0.00154, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00053, val_loss: 0.00168, lr: 4.98E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00048, val_loss: 0.00219, lr: 4.98E-04, _patience: 8\n",
            "Epoch: 13 | train_loss: 0.00048, val_loss: 0.00180, lr: 4.98E-04, _patience: 7\n",
            "Epoch: 14 | train_loss: 0.00039, val_loss: 0.00201, lr: 4.98E-04, _patience: 6\n",
            "Epoch: 15 | train_loss: 0.00034, val_loss: 0.00198, lr: 4.98E-04, _patience: 5\n",
            "Epoch: 16 | train_loss: 0.00029, val_loss: 0.00214, lr: 4.98E-05, _patience: 4\n",
            "Epoch: 17 | train_loss: 0.00024, val_loss: 0.00180, lr: 4.98E-05, _patience: 3\n",
            "Epoch: 18 | train_loss: 0.00018, val_loss: 0.00177, lr: 4.98E-05, _patience: 2\n",
            "Epoch: 19 | train_loss: 0.00017, val_loss: 0.00180, lr: 4.98E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:49:40,927]\u001b[0m Trial 20 finished with value: 0.690346389021688 and parameters: {'embedding_dim': 484, 'num_filters': 479, 'hidden_dim': 504, 'dropout_p': 0.6064430758390457, 'lr': 0.0004982926131849806}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00506, val_loss: 0.00274, lr: 4.38E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00302, val_loss: 0.00238, lr: 4.38E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00229, val_loss: 0.00192, lr: 4.38E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00182, val_loss: 0.00170, lr: 4.38E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00146, val_loss: 0.00157, lr: 4.38E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00117, val_loss: 0.00158, lr: 4.38E-04, _patience: 9\n",
            "Epoch: 7 | train_loss: 0.00095, val_loss: 0.00158, lr: 4.38E-04, _patience: 8\n",
            "Epoch: 8 | train_loss: 0.00074, val_loss: 0.00155, lr: 4.38E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00059, val_loss: 0.00172, lr: 4.38E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00053, val_loss: 0.00172, lr: 4.38E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00044, val_loss: 0.00167, lr: 4.38E-04, _patience: 7\n",
            "Epoch: 12 | train_loss: 0.00037, val_loss: 0.00177, lr: 4.38E-04, _patience: 6\n",
            "Epoch: 13 | train_loss: 0.00029, val_loss: 0.00176, lr: 4.38E-04, _patience: 5\n",
            "Epoch: 14 | train_loss: 0.00026, val_loss: 0.00171, lr: 4.38E-05, _patience: 4\n",
            "Epoch: 15 | train_loss: 0.00022, val_loss: 0.00156, lr: 4.38E-05, _patience: 3\n",
            "Epoch: 16 | train_loss: 0.00016, val_loss: 0.00163, lr: 4.38E-05, _patience: 2\n",
            "Epoch: 17 | train_loss: 0.00016, val_loss: 0.00159, lr: 4.38E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:50:20,167]\u001b[0m Trial 21 finished with value: 0.6943628551999735 and parameters: {'embedding_dim': 465, 'num_filters': 243, 'hidden_dim': 369, 'dropout_p': 0.351063897948802, 'lr': 0.00043796072414598145}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00621, val_loss: 0.00306, lr: 4.87E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00295, val_loss: 0.00236, lr: 4.87E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00223, val_loss: 0.00191, lr: 4.87E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00169, val_loss: 0.00169, lr: 4.87E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00131, val_loss: 0.00162, lr: 4.87E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00100, val_loss: 0.00158, lr: 4.87E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00077, val_loss: 0.00158, lr: 4.87E-04, _patience: 9\n",
            "Epoch: 8 | train_loss: 0.00060, val_loss: 0.00158, lr: 4.87E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00049, val_loss: 0.00157, lr: 4.87E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00041, val_loss: 0.00163, lr: 4.87E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00039, val_loss: 0.00188, lr: 4.87E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00035, val_loss: 0.00210, lr: 4.87E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00035, val_loss: 0.00212, lr: 4.87E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00029, val_loss: 0.00193, lr: 4.87E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00023, val_loss: 0.00202, lr: 4.87E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00017, val_loss: 0.00185, lr: 4.87E-05, _patience: 3\n",
            "Epoch: 17 | train_loss: 0.00011, val_loss: 0.00186, lr: 4.87E-05, _patience: 2\n",
            "Epoch: 18 | train_loss: 0.00010, val_loss: 0.00185, lr: 4.87E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:51:26,594]\u001b[0m Trial 22 finished with value: 0.704333855407378 and parameters: {'embedding_dim': 507, 'num_filters': 373, 'hidden_dim': 402, 'dropout_p': 0.3098677295654228, 'lr': 0.00048684100168162913}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00577, val_loss: 0.00295, lr: 3.38E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00325, val_loss: 0.00243, lr: 3.38E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00249, val_loss: 0.00201, lr: 3.38E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00189, val_loss: 0.00175, lr: 3.38E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00154, val_loss: 0.00169, lr: 3.38E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00129, val_loss: 0.00158, lr: 3.38E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00106, val_loss: 0.00156, lr: 3.38E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00084, val_loss: 0.00154, lr: 3.38E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00070, val_loss: 0.00147, lr: 3.38E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00058, val_loss: 0.00148, lr: 3.38E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00050, val_loss: 0.00153, lr: 3.38E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00043, val_loss: 0.00174, lr: 3.38E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00036, val_loss: 0.00172, lr: 3.38E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00032, val_loss: 0.00180, lr: 3.38E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00027, val_loss: 0.00186, lr: 3.38E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00024, val_loss: 0.00160, lr: 3.38E-05, _patience: 3\n",
            "Epoch: 17 | train_loss: 0.00018, val_loss: 0.00159, lr: 3.38E-05, _patience: 2\n",
            "Epoch: 18 | train_loss: 0.00017, val_loss: 0.00162, lr: 3.38E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:52:28,703]\u001b[0m Trial 23 finished with value: 0.6888445275804926 and parameters: {'embedding_dim': 406, 'num_filters': 432, 'hidden_dim': 417, 'dropout_p': 0.402070930063632, 'lr': 0.0003382212186764488}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00589, val_loss: 0.00287, lr: 4.18E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00316, val_loss: 0.00241, lr: 4.18E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00237, val_loss: 0.00196, lr: 4.18E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00185, val_loss: 0.00175, lr: 4.18E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00152, val_loss: 0.00163, lr: 4.18E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00115, val_loss: 0.00159, lr: 4.18E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00092, val_loss: 0.00157, lr: 4.18E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00075, val_loss: 0.00156, lr: 4.18E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00058, val_loss: 0.00158, lr: 4.18E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00050, val_loss: 0.00168, lr: 4.18E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00047, val_loss: 0.00164, lr: 4.18E-04, _patience: 7\n",
            "Epoch: 12 | train_loss: 0.00039, val_loss: 0.00175, lr: 4.18E-04, _patience: 6\n",
            "Epoch: 13 | train_loss: 0.00037, val_loss: 0.00159, lr: 4.18E-04, _patience: 5\n",
            "Epoch: 14 | train_loss: 0.00031, val_loss: 0.00186, lr: 4.18E-05, _patience: 4\n",
            "Epoch: 15 | train_loss: 0.00025, val_loss: 0.00167, lr: 4.18E-05, _patience: 3\n",
            "Epoch: 16 | train_loss: 0.00018, val_loss: 0.00166, lr: 4.18E-05, _patience: 2\n",
            "Epoch: 17 | train_loss: 0.00017, val_loss: 0.00165, lr: 4.18E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:53:28,380]\u001b[0m Trial 24 finished with value: 0.689974614714511 and parameters: {'embedding_dim': 475, 'num_filters': 371, 'hidden_dim': 471, 'dropout_p': 0.4546831115643709, 'lr': 0.00041817003950477845}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00542, val_loss: 0.00297, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00342, val_loss: 0.00237, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00265, val_loss: 0.00204, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00215, val_loss: 0.00187, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00184, val_loss: 0.00174, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00159, val_loss: 0.00170, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00139, val_loss: 0.00172, lr: 2.61E-04, _patience: 9\n",
            "Epoch: 8 | train_loss: 0.00120, val_loss: 0.00175, lr: 2.61E-04, _patience: 8\n",
            "Epoch: 9 | train_loss: 0.00106, val_loss: 0.00166, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00088, val_loss: 0.00169, lr: 2.61E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00077, val_loss: 0.00158, lr: 2.61E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00067, val_loss: 0.00165, lr: 2.61E-04, _patience: 9\n",
            "Epoch: 13 | train_loss: 0.00057, val_loss: 0.00170, lr: 2.61E-04, _patience: 8\n",
            "Epoch: 14 | train_loss: 0.00055, val_loss: 0.00163, lr: 2.61E-04, _patience: 7\n",
            "Epoch: 15 | train_loss: 0.00049, val_loss: 0.00171, lr: 2.61E-04, _patience: 6\n",
            "Epoch: 16 | train_loss: 0.00044, val_loss: 0.00177, lr: 2.61E-04, _patience: 5\n",
            "Epoch: 17 | train_loss: 0.00039, val_loss: 0.00181, lr: 2.61E-05, _patience: 4\n",
            "Epoch: 18 | train_loss: 0.00035, val_loss: 0.00157, lr: 2.61E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00028, val_loss: 0.00160, lr: 2.61E-05, _patience: 9\n",
            "Epoch: 20 | train_loss: 0.00028, val_loss: 0.00156, lr: 2.61E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00027, val_loss: 0.00158, lr: 2.61E-05, _patience: 9\n",
            "Epoch: 22 | train_loss: 0.00025, val_loss: 0.00156, lr: 2.61E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00025, val_loss: 0.00160, lr: 2.61E-05, _patience: 9\n",
            "Epoch: 24 | train_loss: 0.00024, val_loss: 0.00161, lr: 2.61E-05, _patience: 8\n",
            "Epoch: 25 | train_loss: 0.00023, val_loss: 0.00159, lr: 2.61E-05, _patience: 7\n",
            "Epoch: 26 | train_loss: 0.00023, val_loss: 0.00162, lr: 2.61E-05, _patience: 6\n",
            "Epoch: 27 | train_loss: 0.00023, val_loss: 0.00159, lr: 2.61E-05, _patience: 5\n",
            "Epoch: 28 | train_loss: 0.00022, val_loss: 0.00163, lr: 2.61E-06, _patience: 4\n",
            "Epoch: 29 | train_loss: 0.00023, val_loss: 0.00162, lr: 2.61E-06, _patience: 3\n",
            "Epoch: 30 | train_loss: 0.00022, val_loss: 0.00161, lr: 2.61E-06, _patience: 2\n",
            "Epoch: 31 | train_loss: 0.00022, val_loss: 0.00160, lr: 2.61E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:55:27,807]\u001b[0m Trial 25 finished with value: 0.6959524489590037 and parameters: {'embedding_dim': 510, 'num_filters': 394, 'hidden_dim': 304, 'dropout_p': 0.5192548045270228, 'lr': 0.0002606722598502823}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00594, val_loss: 0.00279, lr: 5.00E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00312, val_loss: 0.00229, lr: 5.00E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00231, val_loss: 0.00190, lr: 5.00E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00182, val_loss: 0.00173, lr: 5.00E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00143, val_loss: 0.00160, lr: 5.00E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00116, val_loss: 0.00155, lr: 5.00E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00090, val_loss: 0.00149, lr: 5.00E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00068, val_loss: 0.00161, lr: 5.00E-04, _patience: 9\n",
            "Epoch: 9 | train_loss: 0.00054, val_loss: 0.00157, lr: 5.00E-04, _patience: 8\n",
            "Epoch: 10 | train_loss: 0.00047, val_loss: 0.00173, lr: 5.00E-04, _patience: 7\n",
            "Epoch: 11 | train_loss: 0.00040, val_loss: 0.00191, lr: 5.00E-04, _patience: 6\n",
            "Epoch: 12 | train_loss: 0.00037, val_loss: 0.00174, lr: 5.00E-04, _patience: 5\n",
            "Epoch: 13 | train_loss: 0.00034, val_loss: 0.00182, lr: 5.00E-05, _patience: 4\n",
            "Epoch: 14 | train_loss: 0.00025, val_loss: 0.00159, lr: 5.00E-05, _patience: 3\n",
            "Epoch: 15 | train_loss: 0.00019, val_loss: 0.00160, lr: 5.00E-05, _patience: 2\n",
            "Epoch: 16 | train_loss: 0.00018, val_loss: 0.00161, lr: 5.00E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:56:18,820]\u001b[0m Trial 26 finished with value: 0.7056624935481121 and parameters: {'embedding_dim': 440, 'num_filters': 361, 'hidden_dim': 351, 'dropout_p': 0.389737006706403, 'lr': 0.0004999261484134036}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00523, val_loss: 0.00271, lr: 3.82E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00311, val_loss: 0.00245, lr: 3.82E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00244, val_loss: 0.00198, lr: 3.82E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00194, val_loss: 0.00178, lr: 3.82E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00157, val_loss: 0.00172, lr: 3.82E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00129, val_loss: 0.00163, lr: 3.82E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00108, val_loss: 0.00163, lr: 3.82E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00088, val_loss: 0.00159, lr: 3.82E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00074, val_loss: 0.00157, lr: 3.82E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00065, val_loss: 0.00158, lr: 3.82E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00053, val_loss: 0.00160, lr: 3.82E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00046, val_loss: 0.00166, lr: 3.82E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00039, val_loss: 0.00168, lr: 3.82E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00035, val_loss: 0.00186, lr: 3.82E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00033, val_loss: 0.00167, lr: 3.82E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00027, val_loss: 0.00170, lr: 3.82E-05, _patience: 3\n",
            "Epoch: 17 | train_loss: 0.00021, val_loss: 0.00162, lr: 3.82E-05, _patience: 2\n",
            "Epoch: 18 | train_loss: 0.00020, val_loss: 0.00162, lr: 3.82E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:57:10,783]\u001b[0m Trial 27 finished with value: 0.6836333663440631 and parameters: {'embedding_dim': 438, 'num_filters': 310, 'hidden_dim': 347, 'dropout_p': 0.42458187561352917, 'lr': 0.00038216070381515664}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00543, val_loss: 0.00316, lr: 3.15E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00348, val_loss: 0.00250, lr: 3.15E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00277, val_loss: 0.00224, lr: 3.15E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00231, val_loss: 0.00199, lr: 3.15E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00195, val_loss: 0.00182, lr: 3.15E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00168, val_loss: 0.00173, lr: 3.15E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00148, val_loss: 0.00162, lr: 3.15E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00128, val_loss: 0.00161, lr: 3.15E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00108, val_loss: 0.00161, lr: 3.15E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00095, val_loss: 0.00153, lr: 3.15E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00082, val_loss: 0.00149, lr: 3.15E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00069, val_loss: 0.00159, lr: 3.15E-04, _patience: 9\n",
            "Epoch: 13 | train_loss: 0.00058, val_loss: 0.00151, lr: 3.15E-04, _patience: 8\n",
            "Epoch: 14 | train_loss: 0.00053, val_loss: 0.00153, lr: 3.15E-04, _patience: 7\n",
            "Epoch: 15 | train_loss: 0.00048, val_loss: 0.00148, lr: 3.15E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00042, val_loss: 0.00164, lr: 3.15E-04, _patience: 9\n",
            "Epoch: 17 | train_loss: 0.00038, val_loss: 0.00150, lr: 3.15E-04, _patience: 8\n",
            "Epoch: 18 | train_loss: 0.00035, val_loss: 0.00161, lr: 3.15E-04, _patience: 7\n",
            "Epoch: 19 | train_loss: 0.00029, val_loss: 0.00167, lr: 3.15E-04, _patience: 6\n",
            "Epoch: 20 | train_loss: 0.00027, val_loss: 0.00173, lr: 3.15E-04, _patience: 5\n",
            "Epoch: 21 | train_loss: 0.00025, val_loss: 0.00175, lr: 3.15E-05, _patience: 4\n",
            "Epoch: 22 | train_loss: 0.00022, val_loss: 0.00160, lr: 3.15E-05, _patience: 3\n",
            "Epoch: 23 | train_loss: 0.00019, val_loss: 0.00160, lr: 3.15E-05, _patience: 2\n",
            "Epoch: 24 | train_loss: 0.00018, val_loss: 0.00160, lr: 3.15E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:58:06,657]\u001b[0m Trial 28 finished with value: 0.6917969982407566 and parameters: {'embedding_dim': 328, 'num_filters': 341, 'hidden_dim': 322, 'dropout_p': 0.4853861295937314, 'lr': 0.0003152052777023375}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00517, val_loss: 0.00351, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00376, val_loss: 0.00261, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00314, val_loss: 0.00248, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00281, val_loss: 0.00229, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00251, val_loss: 0.00215, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00231, val_loss: 0.00201, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00210, val_loss: 0.00189, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00189, val_loss: 0.00182, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00174, val_loss: 0.00178, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00161, val_loss: 0.00175, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00152, val_loss: 0.00170, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00138, val_loss: 0.00167, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00128, val_loss: 0.00164, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00121, val_loss: 0.00164, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00109, val_loss: 0.00162, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00102, val_loss: 0.00159, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00096, val_loss: 0.00167, lr: 1.61E-04, _patience: 9\n",
            "Epoch: 18 | train_loss: 0.00090, val_loss: 0.00152, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00083, val_loss: 0.00161, lr: 1.61E-04, _patience: 9\n",
            "Epoch: 20 | train_loss: 0.00079, val_loss: 0.00157, lr: 1.61E-04, _patience: 8\n",
            "Epoch: 21 | train_loss: 0.00073, val_loss: 0.00156, lr: 1.61E-04, _patience: 7\n",
            "Epoch: 22 | train_loss: 0.00067, val_loss: 0.00167, lr: 1.61E-04, _patience: 6\n",
            "Epoch: 23 | train_loss: 0.00063, val_loss: 0.00151, lr: 1.61E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00057, val_loss: 0.00162, lr: 1.61E-04, _patience: 9\n",
            "Epoch: 25 | train_loss: 0.00053, val_loss: 0.00154, lr: 1.61E-04, _patience: 8\n",
            "Epoch: 26 | train_loss: 0.00049, val_loss: 0.00157, lr: 1.61E-04, _patience: 7\n",
            "Epoch: 27 | train_loss: 0.00048, val_loss: 0.00156, lr: 1.61E-04, _patience: 6\n",
            "Epoch: 28 | train_loss: 0.00045, val_loss: 0.00155, lr: 1.61E-04, _patience: 5\n",
            "Epoch: 29 | train_loss: 0.00042, val_loss: 0.00162, lr: 1.61E-05, _patience: 4\n",
            "Epoch: 30 | train_loss: 0.00041, val_loss: 0.00151, lr: 1.61E-05, _patience: 3\n",
            "Epoch: 31 | train_loss: 0.00038, val_loss: 0.00153, lr: 1.61E-05, _patience: 2\n",
            "Epoch: 32 | train_loss: 0.00037, val_loss: 0.00153, lr: 1.61E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 21:59:28,637]\u001b[0m Trial 29 finished with value: 0.6726796855907661 and parameters: {'embedding_dim': 420, 'num_filters': 283, 'hidden_dim': 233, 'dropout_p': 0.5417688582283965, 'lr': 0.0001607705487990761}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00645, val_loss: 0.00351, lr: 4.09E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00356, val_loss: 0.00256, lr: 4.09E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00273, val_loss: 0.00224, lr: 4.09E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00217, val_loss: 0.00193, lr: 4.09E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00177, val_loss: 0.00176, lr: 4.09E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00152, val_loss: 0.00167, lr: 4.09E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00125, val_loss: 0.00158, lr: 4.09E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00110, val_loss: 0.00159, lr: 4.09E-04, _patience: 9\n",
            "Epoch: 9 | train_loss: 0.00091, val_loss: 0.00154, lr: 4.09E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00077, val_loss: 0.00156, lr: 4.09E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00061, val_loss: 0.00157, lr: 4.09E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00055, val_loss: 0.00171, lr: 4.09E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00047, val_loss: 0.00181, lr: 4.09E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00040, val_loss: 0.00184, lr: 4.09E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00036, val_loss: 0.00180, lr: 4.09E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00032, val_loss: 0.00154, lr: 4.09E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00026, val_loss: 0.00150, lr: 4.09E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00025, val_loss: 0.00153, lr: 4.09E-05, _patience: 9\n",
            "Epoch: 19 | train_loss: 0.00024, val_loss: 0.00153, lr: 4.09E-05, _patience: 8\n",
            "Epoch: 20 | train_loss: 0.00022, val_loss: 0.00154, lr: 4.09E-05, _patience: 7\n",
            "Epoch: 21 | train_loss: 0.00023, val_loss: 0.00154, lr: 4.09E-05, _patience: 6\n",
            "Epoch: 22 | train_loss: 0.00021, val_loss: 0.00154, lr: 4.09E-05, _patience: 5\n",
            "Epoch: 23 | train_loss: 0.00021, val_loss: 0.00155, lr: 4.09E-06, _patience: 4\n",
            "Epoch: 24 | train_loss: 0.00021, val_loss: 0.00155, lr: 4.09E-06, _patience: 3\n",
            "Epoch: 25 | train_loss: 0.00021, val_loss: 0.00155, lr: 4.09E-06, _patience: 2\n",
            "Epoch: 26 | train_loss: 0.00020, val_loss: 0.00155, lr: 4.09E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:00:24,392]\u001b[0m Trial 30 finished with value: 0.6811160369741512 and parameters: {'embedding_dim': 203, 'num_filters': 455, 'hidden_dim': 365, 'dropout_p': 0.38567725908305894, 'lr': 0.0004094186289105576}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00608, val_loss: 0.00294, lr: 4.95E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00298, val_loss: 0.00234, lr: 4.95E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00218, val_loss: 0.00187, lr: 4.95E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00168, val_loss: 0.00174, lr: 4.95E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00133, val_loss: 0.00170, lr: 4.95E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00106, val_loss: 0.00165, lr: 4.95E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00083, val_loss: 0.00156, lr: 4.95E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00063, val_loss: 0.00163, lr: 4.95E-04, _patience: 9\n",
            "Epoch: 9 | train_loss: 0.00047, val_loss: 0.00175, lr: 4.95E-04, _patience: 8\n",
            "Epoch: 10 | train_loss: 0.00041, val_loss: 0.00183, lr: 4.95E-04, _patience: 7\n",
            "Epoch: 11 | train_loss: 0.00034, val_loss: 0.00189, lr: 4.95E-04, _patience: 6\n",
            "Epoch: 12 | train_loss: 0.00031, val_loss: 0.00191, lr: 4.95E-04, _patience: 5\n",
            "Epoch: 13 | train_loss: 0.00031, val_loss: 0.00202, lr: 4.95E-05, _patience: 4\n",
            "Epoch: 14 | train_loss: 0.00024, val_loss: 0.00174, lr: 4.95E-05, _patience: 3\n",
            "Epoch: 15 | train_loss: 0.00015, val_loss: 0.00167, lr: 4.95E-05, _patience: 2\n",
            "Epoch: 16 | train_loss: 0.00014, val_loss: 0.00169, lr: 4.95E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:01:21,693]\u001b[0m Trial 31 finished with value: 0.6787386687018724 and parameters: {'embedding_dim': 512, 'num_filters': 364, 'hidden_dim': 427, 'dropout_p': 0.3256200732201236, 'lr': 0.0004946070893241252}. Best is trial 15 with value: 0.7081352359515858.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00628, val_loss: 0.00306, lr: 4.94E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00314, val_loss: 0.00243, lr: 4.94E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00231, val_loss: 0.00200, lr: 4.94E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00178, val_loss: 0.00173, lr: 4.94E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00139, val_loss: 0.00168, lr: 4.94E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00110, val_loss: 0.00158, lr: 4.94E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00084, val_loss: 0.00156, lr: 4.94E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00063, val_loss: 0.00161, lr: 4.94E-04, _patience: 9\n",
            "Epoch: 9 | train_loss: 0.00052, val_loss: 0.00156, lr: 4.94E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00043, val_loss: 0.00175, lr: 4.94E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00036, val_loss: 0.00173, lr: 4.94E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00032, val_loss: 0.00189, lr: 4.94E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00027, val_loss: 0.00188, lr: 4.94E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00025, val_loss: 0.00203, lr: 4.94E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00021, val_loss: 0.00208, lr: 4.94E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00016, val_loss: 0.00180, lr: 4.94E-05, _patience: 3\n",
            "Epoch: 17 | train_loss: 0.00012, val_loss: 0.00179, lr: 4.94E-05, _patience: 2\n",
            "Epoch: 18 | train_loss: 0.00010, val_loss: 0.00181, lr: 4.94E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:02:27,802]\u001b[0m Trial 32 finished with value: 0.7102877118012281 and parameters: {'embedding_dim': 472, 'num_filters': 398, 'hidden_dim': 402, 'dropout_p': 0.37460230139713574, 'lr': 0.0004944035411985671}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00452, val_loss: 0.00349, lr: 9.14E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00330, val_loss: 0.00256, lr: 9.14E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00280, val_loss: 0.00242, lr: 9.14E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00256, val_loss: 0.00228, lr: 9.14E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00231, val_loss: 0.00212, lr: 9.14E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00212, val_loss: 0.00202, lr: 9.14E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00191, val_loss: 0.00188, lr: 9.14E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00178, val_loss: 0.00181, lr: 9.14E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00165, val_loss: 0.00172, lr: 9.14E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00153, val_loss: 0.00167, lr: 9.14E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00139, val_loss: 0.00162, lr: 9.14E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00133, val_loss: 0.00159, lr: 9.14E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00120, val_loss: 0.00156, lr: 9.14E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00115, val_loss: 0.00152, lr: 9.14E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00107, val_loss: 0.00153, lr: 9.14E-05, _patience: 9\n",
            "Epoch: 16 | train_loss: 0.00100, val_loss: 0.00153, lr: 9.14E-05, _patience: 8\n",
            "Epoch: 17 | train_loss: 0.00093, val_loss: 0.00149, lr: 9.14E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00086, val_loss: 0.00152, lr: 9.14E-05, _patience: 9\n",
            "Epoch: 19 | train_loss: 0.00080, val_loss: 0.00151, lr: 9.14E-05, _patience: 8\n",
            "Epoch: 20 | train_loss: 0.00073, val_loss: 0.00146, lr: 9.14E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00068, val_loss: 0.00152, lr: 9.14E-05, _patience: 9\n",
            "Epoch: 22 | train_loss: 0.00064, val_loss: 0.00149, lr: 9.14E-05, _patience: 8\n",
            "Epoch: 23 | train_loss: 0.00062, val_loss: 0.00147, lr: 9.14E-05, _patience: 7\n",
            "Epoch: 24 | train_loss: 0.00055, val_loss: 0.00148, lr: 9.14E-05, _patience: 6\n",
            "Epoch: 25 | train_loss: 0.00052, val_loss: 0.00155, lr: 9.14E-05, _patience: 5\n",
            "Epoch: 26 | train_loss: 0.00051, val_loss: 0.00151, lr: 9.14E-06, _patience: 4\n",
            "Epoch: 27 | train_loss: 0.00045, val_loss: 0.00144, lr: 9.14E-06, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00044, val_loss: 0.00143, lr: 9.14E-06, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00043, val_loss: 0.00144, lr: 9.14E-06, _patience: 9\n",
            "Epoch: 30 | train_loss: 0.00044, val_loss: 0.00143, lr: 9.14E-06, _patience: 8\n",
            "Epoch: 31 | train_loss: 0.00042, val_loss: 0.00142, lr: 9.14E-06, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00041, val_loss: 0.00144, lr: 9.14E-06, _patience: 9\n",
            "Epoch: 33 | train_loss: 0.00040, val_loss: 0.00144, lr: 9.14E-06, _patience: 8\n",
            "Epoch: 34 | train_loss: 0.00039, val_loss: 0.00145, lr: 9.14E-06, _patience: 7\n",
            "Epoch: 35 | train_loss: 0.00040, val_loss: 0.00143, lr: 9.14E-06, _patience: 6\n",
            "Epoch: 36 | train_loss: 0.00040, val_loss: 0.00142, lr: 9.14E-06, _patience: 10\n",
            "Epoch: 37 | train_loss: 0.00039, val_loss: 0.00144, lr: 9.14E-06, _patience: 9\n",
            "Epoch: 38 | train_loss: 0.00039, val_loss: 0.00143, lr: 9.14E-06, _patience: 8\n",
            "Epoch: 39 | train_loss: 0.00039, val_loss: 0.00143, lr: 9.14E-06, _patience: 7\n",
            "Epoch: 40 | train_loss: 0.00039, val_loss: 0.00144, lr: 9.14E-06, _patience: 6\n",
            "Epoch: 41 | train_loss: 0.00038, val_loss: 0.00143, lr: 9.14E-06, _patience: 5\n",
            "Epoch: 42 | train_loss: 0.00037, val_loss: 0.00144, lr: 9.14E-07, _patience: 4\n",
            "Epoch: 43 | train_loss: 0.00038, val_loss: 0.00144, lr: 9.14E-07, _patience: 3\n",
            "Epoch: 44 | train_loss: 0.00037, val_loss: 0.00144, lr: 9.14E-07, _patience: 2\n",
            "Epoch: 45 | train_loss: 0.00038, val_loss: 0.00144, lr: 9.14E-07, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:05:10,049]\u001b[0m Trial 33 finished with value: 0.6790796462460503 and parameters: {'embedding_dim': 462, 'num_filters': 409, 'hidden_dim': 348, 'dropout_p': 0.4331617486149646, 'lr': 9.138542693941112e-05}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00564, val_loss: 0.00284, lr: 4.42E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00306, val_loss: 0.00241, lr: 4.42E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00235, val_loss: 0.00198, lr: 4.42E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00183, val_loss: 0.00175, lr: 4.42E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00146, val_loss: 0.00165, lr: 4.42E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00118, val_loss: 0.00162, lr: 4.42E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00093, val_loss: 0.00153, lr: 4.42E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00072, val_loss: 0.00159, lr: 4.42E-04, _patience: 9\n",
            "Epoch: 9 | train_loss: 0.00058, val_loss: 0.00159, lr: 4.42E-04, _patience: 8\n",
            "Epoch: 10 | train_loss: 0.00045, val_loss: 0.00168, lr: 4.42E-04, _patience: 7\n",
            "Epoch: 11 | train_loss: 0.00041, val_loss: 0.00175, lr: 4.42E-04, _patience: 6\n",
            "Epoch: 12 | train_loss: 0.00038, val_loss: 0.00177, lr: 4.42E-04, _patience: 5\n",
            "Epoch: 13 | train_loss: 0.00037, val_loss: 0.00178, lr: 4.42E-05, _patience: 4\n",
            "Epoch: 14 | train_loss: 0.00027, val_loss: 0.00168, lr: 4.42E-05, _patience: 3\n",
            "Epoch: 15 | train_loss: 0.00020, val_loss: 0.00167, lr: 4.42E-05, _patience: 2\n",
            "Epoch: 16 | train_loss: 0.00018, val_loss: 0.00166, lr: 4.42E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:06:01,557]\u001b[0m Trial 34 finished with value: 0.6866179960249056 and parameters: {'embedding_dim': 481, 'num_filters': 309, 'hidden_dim': 456, 'dropout_p': 0.3715332291039401, 'lr': 0.00044201913228164184}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00638, val_loss: 0.00298, lr: 3.67E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00350, val_loss: 0.00239, lr: 3.67E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00269, val_loss: 0.00207, lr: 3.67E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00214, val_loss: 0.00183, lr: 3.67E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00173, val_loss: 0.00168, lr: 3.67E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00150, val_loss: 0.00162, lr: 3.67E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00125, val_loss: 0.00164, lr: 3.67E-04, _patience: 9\n",
            "Epoch: 8 | train_loss: 0.00109, val_loss: 0.00163, lr: 3.67E-04, _patience: 8\n",
            "Epoch: 9 | train_loss: 0.00093, val_loss: 0.00156, lr: 3.67E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00077, val_loss: 0.00159, lr: 3.67E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00069, val_loss: 0.00162, lr: 3.67E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00058, val_loss: 0.00169, lr: 3.67E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00050, val_loss: 0.00171, lr: 3.67E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00049, val_loss: 0.00178, lr: 3.67E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00044, val_loss: 0.00197, lr: 3.67E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00038, val_loss: 0.00156, lr: 3.67E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00028, val_loss: 0.00166, lr: 3.67E-05, _patience: 9\n",
            "Epoch: 18 | train_loss: 0.00026, val_loss: 0.00162, lr: 3.67E-05, _patience: 8\n",
            "Epoch: 19 | train_loss: 0.00026, val_loss: 0.00162, lr: 3.67E-05, _patience: 7\n",
            "Epoch: 20 | train_loss: 0.00024, val_loss: 0.00164, lr: 3.67E-05, _patience: 6\n",
            "Epoch: 21 | train_loss: 0.00024, val_loss: 0.00164, lr: 3.67E-05, _patience: 5\n",
            "Epoch: 22 | train_loss: 0.00022, val_loss: 0.00162, lr: 3.67E-06, _patience: 4\n",
            "Epoch: 23 | train_loss: 0.00022, val_loss: 0.00162, lr: 3.67E-06, _patience: 3\n",
            "Epoch: 24 | train_loss: 0.00022, val_loss: 0.00163, lr: 3.67E-06, _patience: 2\n",
            "Epoch: 25 | train_loss: 0.00022, val_loss: 0.00163, lr: 3.67E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:07:33,425]\u001b[0m Trial 35 finished with value: 0.6895817063963423 and parameters: {'embedding_dim': 441, 'num_filters': 440, 'hidden_dim': 263, 'dropout_p': 0.48312288442939505, 'lr': 0.00036741064775232875}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00697, val_loss: 0.00303, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00326, val_loss: 0.00248, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00240, val_loss: 0.00203, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00190, val_loss: 0.00179, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00149, val_loss: 0.00169, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00119, val_loss: 0.00157, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00093, val_loss: 0.00161, lr: 4.98E-04, _patience: 9\n",
            "Epoch: 8 | train_loss: 0.00074, val_loss: 0.00160, lr: 4.98E-04, _patience: 8\n",
            "Epoch: 9 | train_loss: 0.00058, val_loss: 0.00156, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00045, val_loss: 0.00167, lr: 4.98E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00041, val_loss: 0.00170, lr: 4.98E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00034, val_loss: 0.00183, lr: 4.98E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00030, val_loss: 0.00200, lr: 4.98E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00027, val_loss: 0.00205, lr: 4.98E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00025, val_loss: 0.00212, lr: 4.98E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00021, val_loss: 0.00168, lr: 4.98E-05, _patience: 3\n",
            "Epoch: 17 | train_loss: 0.00014, val_loss: 0.00165, lr: 4.98E-05, _patience: 2\n",
            "Epoch: 18 | train_loss: 0.00012, val_loss: 0.00172, lr: 4.98E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:08:36,516]\u001b[0m Trial 36 finished with value: 0.6948986757829166 and parameters: {'embedding_dim': 383, 'num_filters': 471, 'hidden_dim': 388, 'dropout_p': 0.3516392586441111, 'lr': 0.000498392386803151}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00577, val_loss: 0.00291, lr: 3.06E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00318, val_loss: 0.00247, lr: 3.06E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00254, val_loss: 0.00206, lr: 3.06E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00197, val_loss: 0.00181, lr: 3.06E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00160, val_loss: 0.00169, lr: 3.06E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00133, val_loss: 0.00159, lr: 3.06E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00110, val_loss: 0.00155, lr: 3.06E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00091, val_loss: 0.00154, lr: 3.06E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00076, val_loss: 0.00156, lr: 3.06E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00062, val_loss: 0.00147, lr: 3.06E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00050, val_loss: 0.00154, lr: 3.06E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00042, val_loss: 0.00159, lr: 3.06E-04, _patience: 8\n",
            "Epoch: 13 | train_loss: 0.00036, val_loss: 0.00160, lr: 3.06E-04, _patience: 7\n",
            "Epoch: 14 | train_loss: 0.00031, val_loss: 0.00159, lr: 3.06E-04, _patience: 6\n",
            "Epoch: 15 | train_loss: 0.00029, val_loss: 0.00169, lr: 3.06E-04, _patience: 5\n",
            "Epoch: 16 | train_loss: 0.00026, val_loss: 0.00175, lr: 3.06E-05, _patience: 4\n",
            "Epoch: 17 | train_loss: 0.00023, val_loss: 0.00161, lr: 3.06E-05, _patience: 3\n",
            "Epoch: 18 | train_loss: 0.00018, val_loss: 0.00155, lr: 3.06E-05, _patience: 2\n",
            "Epoch: 19 | train_loss: 0.00017, val_loss: 0.00159, lr: 3.06E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:09:48,462]\u001b[0m Trial 37 finished with value: 0.6989682101555443 and parameters: {'embedding_dim': 488, 'num_filters': 394, 'hidden_dim': 485, 'dropout_p': 0.4653716719987929, 'lr': 0.00030615883162829407}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00624, val_loss: 0.00287, lr: 4.35E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00353, val_loss: 0.00252, lr: 4.35E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00269, val_loss: 0.00211, lr: 4.35E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00221, val_loss: 0.00185, lr: 4.35E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00180, val_loss: 0.00175, lr: 4.35E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00150, val_loss: 0.00167, lr: 4.35E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00127, val_loss: 0.00164, lr: 4.35E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00105, val_loss: 0.00164, lr: 4.35E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00086, val_loss: 0.00154, lr: 4.35E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00072, val_loss: 0.00168, lr: 4.35E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00061, val_loss: 0.00167, lr: 4.35E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00055, val_loss: 0.00159, lr: 4.35E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00048, val_loss: 0.00173, lr: 4.35E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00047, val_loss: 0.00187, lr: 4.35E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00039, val_loss: 0.00174, lr: 4.35E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00033, val_loss: 0.00161, lr: 4.35E-05, _patience: 3\n",
            "Epoch: 17 | train_loss: 0.00025, val_loss: 0.00159, lr: 4.35E-05, _patience: 2\n",
            "Epoch: 18 | train_loss: 0.00025, val_loss: 0.00161, lr: 4.35E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:10:43,089]\u001b[0m Trial 38 finished with value: 0.7073815720260342 and parameters: {'embedding_dim': 420, 'num_filters': 353, 'hidden_dim': 322, 'dropout_p': 0.5195856635041117, 'lr': 0.0004354849644707854}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00499, val_loss: 0.00326, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00335, val_loss: 0.00253, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00282, val_loss: 0.00231, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00241, val_loss: 0.00207, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00210, val_loss: 0.00190, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00183, val_loss: 0.00180, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00163, val_loss: 0.00173, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00145, val_loss: 0.00166, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00132, val_loss: 0.00164, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00116, val_loss: 0.00157, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00104, val_loss: 0.00162, lr: 2.40E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00092, val_loss: 0.00156, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00084, val_loss: 0.00161, lr: 2.40E-04, _patience: 9\n",
            "Epoch: 14 | train_loss: 0.00077, val_loss: 0.00153, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00068, val_loss: 0.00156, lr: 2.40E-04, _patience: 9\n",
            "Epoch: 16 | train_loss: 0.00062, val_loss: 0.00147, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00054, val_loss: 0.00155, lr: 2.40E-04, _patience: 9\n",
            "Epoch: 18 | train_loss: 0.00050, val_loss: 0.00164, lr: 2.40E-04, _patience: 8\n",
            "Epoch: 19 | train_loss: 0.00046, val_loss: 0.00178, lr: 2.40E-04, _patience: 7\n",
            "Epoch: 20 | train_loss: 0.00044, val_loss: 0.00169, lr: 2.40E-04, _patience: 6\n",
            "Epoch: 21 | train_loss: 0.00041, val_loss: 0.00169, lr: 2.40E-04, _patience: 5\n",
            "Epoch: 22 | train_loss: 0.00037, val_loss: 0.00183, lr: 2.40E-05, _patience: 4\n",
            "Epoch: 23 | train_loss: 0.00032, val_loss: 0.00153, lr: 2.40E-05, _patience: 3\n",
            "Epoch: 24 | train_loss: 0.00028, val_loss: 0.00157, lr: 2.40E-05, _patience: 2\n",
            "Epoch: 25 | train_loss: 0.00028, val_loss: 0.00155, lr: 2.40E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:11:35,714]\u001b[0m Trial 39 finished with value: 0.6735362330036719 and parameters: {'embedding_dim': 431, 'num_filters': 256, 'hidden_dim': 307, 'dropout_p': 0.518570082923261, 'lr': 0.0002404127348161911}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00582, val_loss: 0.00314, lr: 3.45E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00360, val_loss: 0.00254, lr: 3.45E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00290, val_loss: 0.00225, lr: 3.45E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00241, val_loss: 0.00203, lr: 3.45E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00207, val_loss: 0.00185, lr: 3.45E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00178, val_loss: 0.00170, lr: 3.45E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00155, val_loss: 0.00164, lr: 3.45E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00131, val_loss: 0.00158, lr: 3.45E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00120, val_loss: 0.00153, lr: 3.45E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00101, val_loss: 0.00159, lr: 3.45E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00089, val_loss: 0.00153, lr: 3.45E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00080, val_loss: 0.00158, lr: 3.45E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00070, val_loss: 0.00160, lr: 3.45E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00063, val_loss: 0.00157, lr: 3.45E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00055, val_loss: 0.00168, lr: 3.45E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00049, val_loss: 0.00152, lr: 3.45E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00041, val_loss: 0.00152, lr: 3.45E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00038, val_loss: 0.00152, lr: 3.45E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00039, val_loss: 0.00151, lr: 3.45E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00038, val_loss: 0.00152, lr: 3.45E-05, _patience: 9\n",
            "Epoch: 21 | train_loss: 0.00037, val_loss: 0.00152, lr: 3.45E-05, _patience: 8\n",
            "Epoch: 22 | train_loss: 0.00035, val_loss: 0.00154, lr: 3.45E-05, _patience: 7\n",
            "Epoch: 23 | train_loss: 0.00034, val_loss: 0.00149, lr: 3.45E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00034, val_loss: 0.00153, lr: 3.45E-05, _patience: 9\n",
            "Epoch: 25 | train_loss: 0.00034, val_loss: 0.00154, lr: 3.45E-05, _patience: 8\n",
            "Epoch: 26 | train_loss: 0.00032, val_loss: 0.00152, lr: 3.45E-05, _patience: 7\n",
            "Epoch: 27 | train_loss: 0.00032, val_loss: 0.00153, lr: 3.45E-05, _patience: 6\n",
            "Epoch: 28 | train_loss: 0.00031, val_loss: 0.00155, lr: 3.45E-05, _patience: 5\n",
            "Epoch: 29 | train_loss: 0.00030, val_loss: 0.00153, lr: 3.45E-06, _patience: 4\n",
            "Epoch: 30 | train_loss: 0.00031, val_loss: 0.00154, lr: 3.45E-06, _patience: 3\n",
            "Epoch: 31 | train_loss: 0.00031, val_loss: 0.00154, lr: 3.45E-06, _patience: 2\n",
            "Epoch: 32 | train_loss: 0.00029, val_loss: 0.00154, lr: 3.45E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:12:52,245]\u001b[0m Trial 40 finished with value: 0.685355799566251 and parameters: {'embedding_dim': 341, 'num_filters': 337, 'hidden_dim': 325, 'dropout_p': 0.5839101733472284, 'lr': 0.00034518530245696276}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00606, val_loss: 0.00284, lr: 4.38E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00318, val_loss: 0.00248, lr: 4.38E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00248, val_loss: 0.00202, lr: 4.38E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00197, val_loss: 0.00176, lr: 4.38E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00155, val_loss: 0.00168, lr: 4.38E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00128, val_loss: 0.00161, lr: 4.38E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00103, val_loss: 0.00159, lr: 4.38E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00084, val_loss: 0.00154, lr: 4.38E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00064, val_loss: 0.00157, lr: 4.38E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00056, val_loss: 0.00161, lr: 4.38E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00046, val_loss: 0.00167, lr: 4.38E-04, _patience: 7\n",
            "Epoch: 12 | train_loss: 0.00036, val_loss: 0.00188, lr: 4.38E-04, _patience: 6\n",
            "Epoch: 13 | train_loss: 0.00033, val_loss: 0.00180, lr: 4.38E-04, _patience: 5\n",
            "Epoch: 14 | train_loss: 0.00027, val_loss: 0.00183, lr: 4.38E-05, _patience: 4\n",
            "Epoch: 15 | train_loss: 0.00023, val_loss: 0.00167, lr: 4.38E-05, _patience: 3\n",
            "Epoch: 16 | train_loss: 0.00018, val_loss: 0.00165, lr: 4.38E-05, _patience: 2\n",
            "Epoch: 17 | train_loss: 0.00017, val_loss: 0.00165, lr: 4.38E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:13:48,445]\u001b[0m Trial 41 finished with value: 0.6887995256130629 and parameters: {'embedding_dim': 460, 'num_filters': 354, 'hidden_dim': 362, 'dropout_p': 0.4236308239363996, 'lr': 0.0004383276822243548}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00561, val_loss: 0.00285, lr: 4.39E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00314, val_loss: 0.00248, lr: 4.39E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00241, val_loss: 0.00200, lr: 4.39E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00191, val_loss: 0.00177, lr: 4.39E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00151, val_loss: 0.00171, lr: 4.39E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00125, val_loss: 0.00162, lr: 4.39E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00100, val_loss: 0.00163, lr: 4.39E-04, _patience: 9\n",
            "Epoch: 8 | train_loss: 0.00080, val_loss: 0.00165, lr: 4.39E-04, _patience: 8\n",
            "Epoch: 9 | train_loss: 0.00067, val_loss: 0.00168, lr: 4.39E-04, _patience: 7\n",
            "Epoch: 10 | train_loss: 0.00053, val_loss: 0.00162, lr: 4.39E-04, _patience: 6\n",
            "Epoch: 11 | train_loss: 0.00047, val_loss: 0.00168, lr: 4.39E-04, _patience: 5\n",
            "Epoch: 12 | train_loss: 0.00044, val_loss: 0.00179, lr: 4.39E-05, _patience: 4\n",
            "Epoch: 13 | train_loss: 0.00037, val_loss: 0.00164, lr: 4.39E-05, _patience: 3\n",
            "Epoch: 14 | train_loss: 0.00029, val_loss: 0.00161, lr: 4.39E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00026, val_loss: 0.00160, lr: 4.39E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00024, val_loss: 0.00163, lr: 4.39E-05, _patience: 9\n",
            "Epoch: 17 | train_loss: 0.00023, val_loss: 0.00163, lr: 4.39E-05, _patience: 8\n",
            "Epoch: 18 | train_loss: 0.00023, val_loss: 0.00162, lr: 4.39E-05, _patience: 7\n",
            "Epoch: 19 | train_loss: 0.00022, val_loss: 0.00165, lr: 4.39E-05, _patience: 6\n",
            "Epoch: 20 | train_loss: 0.00021, val_loss: 0.00164, lr: 4.39E-05, _patience: 5\n",
            "Epoch: 21 | train_loss: 0.00020, val_loss: 0.00163, lr: 4.39E-06, _patience: 4\n",
            "Epoch: 22 | train_loss: 0.00020, val_loss: 0.00164, lr: 4.39E-06, _patience: 3\n",
            "Epoch: 23 | train_loss: 0.00020, val_loss: 0.00164, lr: 4.39E-06, _patience: 2\n",
            "Epoch: 24 | train_loss: 0.00019, val_loss: 0.00164, lr: 4.39E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:15:07,422]\u001b[0m Trial 42 finished with value: 0.6932799500543302 and parameters: {'embedding_dim': 493, 'num_filters': 322, 'hidden_dim': 289, 'dropout_p': 0.3939173782786757, 'lr': 0.0004393012452199026}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00714, val_loss: 0.00314, lr: 3.86E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00365, val_loss: 0.00257, lr: 3.86E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00288, val_loss: 0.00220, lr: 3.86E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00236, val_loss: 0.00191, lr: 3.86E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00199, val_loss: 0.00179, lr: 3.86E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00171, val_loss: 0.00167, lr: 3.86E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00141, val_loss: 0.00168, lr: 3.86E-04, _patience: 9\n",
            "Epoch: 8 | train_loss: 0.00127, val_loss: 0.00160, lr: 3.86E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00104, val_loss: 0.00168, lr: 3.86E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00092, val_loss: 0.00158, lr: 3.86E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00076, val_loss: 0.00164, lr: 3.86E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00062, val_loss: 0.00166, lr: 3.86E-04, _patience: 8\n",
            "Epoch: 13 | train_loss: 0.00059, val_loss: 0.00170, lr: 3.86E-04, _patience: 7\n",
            "Epoch: 14 | train_loss: 0.00050, val_loss: 0.00152, lr: 3.86E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00045, val_loss: 0.00167, lr: 3.86E-04, _patience: 9\n",
            "Epoch: 16 | train_loss: 0.00040, val_loss: 0.00179, lr: 3.86E-04, _patience: 8\n",
            "Epoch: 17 | train_loss: 0.00038, val_loss: 0.00156, lr: 3.86E-04, _patience: 7\n",
            "Epoch: 18 | train_loss: 0.00034, val_loss: 0.00185, lr: 3.86E-04, _patience: 6\n",
            "Epoch: 19 | train_loss: 0.00032, val_loss: 0.00193, lr: 3.86E-04, _patience: 5\n",
            "Epoch: 20 | train_loss: 0.00029, val_loss: 0.00178, lr: 3.86E-05, _patience: 4\n",
            "Epoch: 21 | train_loss: 0.00023, val_loss: 0.00171, lr: 3.86E-05, _patience: 3\n",
            "Epoch: 22 | train_loss: 0.00019, val_loss: 0.00175, lr: 3.86E-05, _patience: 2\n",
            "Epoch: 23 | train_loss: 0.00019, val_loss: 0.00175, lr: 3.86E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:16:27,168]\u001b[0m Trial 43 finished with value: 0.6945316004719305 and parameters: {'embedding_dim': 426, 'num_filters': 413, 'hidden_dim': 389, 'dropout_p': 0.628876765173201, 'lr': 0.00038592860137727785}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00591, val_loss: 0.00278, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00335, val_loss: 0.00247, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00257, val_loss: 0.00205, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00207, val_loss: 0.00183, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00169, val_loss: 0.00169, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00138, val_loss: 0.00160, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00115, val_loss: 0.00154, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00093, val_loss: 0.00157, lr: 4.96E-04, _patience: 9\n",
            "Epoch: 9 | train_loss: 0.00079, val_loss: 0.00148, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00064, val_loss: 0.00165, lr: 4.96E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00054, val_loss: 0.00162, lr: 4.96E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00046, val_loss: 0.00167, lr: 4.96E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00040, val_loss: 0.00170, lr: 4.96E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00036, val_loss: 0.00173, lr: 4.96E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00033, val_loss: 0.00182, lr: 4.96E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00029, val_loss: 0.00161, lr: 4.96E-05, _patience: 3\n",
            "Epoch: 17 | train_loss: 0.00022, val_loss: 0.00169, lr: 4.96E-05, _patience: 2\n",
            "Epoch: 18 | train_loss: 0.00020, val_loss: 0.00163, lr: 4.96E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:17:14,556]\u001b[0m Trial 44 finished with value: 0.675960007342357 and parameters: {'embedding_dim': 394, 'num_filters': 301, 'hidden_dim': 334, 'dropout_p': 0.5041260011891522, 'lr': 0.000496400898771724}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00587, val_loss: 0.00273, lr: 4.52E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00313, val_loss: 0.00230, lr: 4.52E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00231, val_loss: 0.00198, lr: 4.52E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00179, val_loss: 0.00180, lr: 4.52E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00139, val_loss: 0.00163, lr: 4.52E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00109, val_loss: 0.00158, lr: 4.52E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00084, val_loss: 0.00153, lr: 4.52E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00063, val_loss: 0.00156, lr: 4.52E-04, _patience: 9\n",
            "Epoch: 9 | train_loss: 0.00053, val_loss: 0.00163, lr: 4.52E-04, _patience: 8\n",
            "Epoch: 10 | train_loss: 0.00045, val_loss: 0.00175, lr: 4.52E-04, _patience: 7\n",
            "Epoch: 11 | train_loss: 0.00038, val_loss: 0.00179, lr: 4.52E-04, _patience: 6\n",
            "Epoch: 12 | train_loss: 0.00031, val_loss: 0.00196, lr: 4.52E-04, _patience: 5\n",
            "Epoch: 13 | train_loss: 0.00033, val_loss: 0.00204, lr: 4.52E-05, _patience: 4\n",
            "Epoch: 14 | train_loss: 0.00029, val_loss: 0.00178, lr: 4.52E-05, _patience: 3\n",
            "Epoch: 15 | train_loss: 0.00018, val_loss: 0.00169, lr: 4.52E-05, _patience: 2\n",
            "Epoch: 16 | train_loss: 0.00016, val_loss: 0.00168, lr: 4.52E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:18:16,998]\u001b[0m Trial 45 finished with value: 0.6906438191943152 and parameters: {'embedding_dim': 498, 'num_filters': 388, 'hidden_dim': 353, 'dropout_p': 0.3708056474012058, 'lr': 0.0004523010115292895}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00569, val_loss: 0.00295, lr: 3.28E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00342, val_loss: 0.00245, lr: 3.28E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00280, val_loss: 0.00211, lr: 3.28E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00236, val_loss: 0.00191, lr: 3.28E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00198, val_loss: 0.00178, lr: 3.28E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00170, val_loss: 0.00172, lr: 3.28E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00150, val_loss: 0.00162, lr: 3.28E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00128, val_loss: 0.00155, lr: 3.28E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00110, val_loss: 0.00154, lr: 3.28E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00095, val_loss: 0.00158, lr: 3.28E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00081, val_loss: 0.00155, lr: 3.28E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00072, val_loss: 0.00163, lr: 3.28E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00066, val_loss: 0.00153, lr: 3.28E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00058, val_loss: 0.00162, lr: 3.28E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00050, val_loss: 0.00183, lr: 3.28E-04, _patience: 8\n",
            "Epoch: 16 | train_loss: 0.00047, val_loss: 0.00191, lr: 3.28E-04, _patience: 7\n",
            "Epoch: 17 | train_loss: 0.00050, val_loss: 0.00187, lr: 3.28E-04, _patience: 6\n",
            "Epoch: 18 | train_loss: 0.00044, val_loss: 0.00157, lr: 3.28E-04, _patience: 5\n",
            "Epoch: 19 | train_loss: 0.00040, val_loss: 0.00196, lr: 3.28E-05, _patience: 4\n",
            "Epoch: 20 | train_loss: 0.00035, val_loss: 0.00153, lr: 3.28E-05, _patience: 3\n",
            "Epoch: 21 | train_loss: 0.00027, val_loss: 0.00169, lr: 3.28E-05, _patience: 2\n",
            "Epoch: 22 | train_loss: 0.00026, val_loss: 0.00161, lr: 3.28E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:19:29,547]\u001b[0m Trial 46 finished with value: 0.6839549509112915 and parameters: {'embedding_dim': 473, 'num_filters': 349, 'hidden_dim': 249, 'dropout_p': 0.5495169377706061, 'lr': 0.0003280497002570248}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00450, val_loss: 0.00336, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00334, val_loss: 0.00267, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00282, val_loss: 0.00251, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00260, val_loss: 0.00239, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00241, val_loss: 0.00226, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00228, val_loss: 0.00216, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00210, val_loss: 0.00205, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00197, val_loss: 0.00197, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00182, val_loss: 0.00189, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00172, val_loss: 0.00181, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00157, val_loss: 0.00175, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00149, val_loss: 0.00171, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00141, val_loss: 0.00165, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00131, val_loss: 0.00160, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00123, val_loss: 0.00159, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00118, val_loss: 0.00157, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00109, val_loss: 0.00156, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00104, val_loss: 0.00155, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00097, val_loss: 0.00152, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00092, val_loss: 0.00151, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00088, val_loss: 0.00150, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00083, val_loss: 0.00149, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00080, val_loss: 0.00147, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00075, val_loss: 0.00145, lr: 6.27E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00071, val_loss: 0.00146, lr: 6.27E-05, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00067, val_loss: 0.00148, lr: 6.27E-05, _patience: 8\n",
            "Epoch: 27 | train_loss: 0.00062, val_loss: 0.00149, lr: 6.27E-05, _patience: 7\n",
            "Epoch: 28 | train_loss: 0.00060, val_loss: 0.00147, lr: 6.27E-05, _patience: 6\n",
            "Epoch: 29 | train_loss: 0.00056, val_loss: 0.00149, lr: 6.27E-05, _patience: 5\n",
            "Epoch: 30 | train_loss: 0.00054, val_loss: 0.00145, lr: 6.27E-06, _patience: 4\n",
            "Epoch: 31 | train_loss: 0.00051, val_loss: 0.00142, lr: 6.27E-06, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00049, val_loss: 0.00142, lr: 6.27E-06, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00049, val_loss: 0.00142, lr: 6.27E-06, _patience: 9\n",
            "Epoch: 34 | train_loss: 0.00047, val_loss: 0.00142, lr: 6.27E-06, _patience: 8\n",
            "Epoch: 35 | train_loss: 0.00047, val_loss: 0.00142, lr: 6.27E-06, _patience: 7\n",
            "Epoch: 36 | train_loss: 0.00047, val_loss: 0.00142, lr: 6.27E-06, _patience: 6\n",
            "Epoch: 37 | train_loss: 0.00047, val_loss: 0.00142, lr: 6.27E-06, _patience: 5\n",
            "Epoch: 38 | train_loss: 0.00047, val_loss: 0.00142, lr: 6.27E-07, _patience: 4\n",
            "Epoch: 39 | train_loss: 0.00048, val_loss: 0.00142, lr: 6.27E-07, _patience: 3\n",
            "Epoch: 40 | train_loss: 0.00047, val_loss: 0.00142, lr: 6.27E-07, _patience: 2\n",
            "Epoch: 41 | train_loss: 0.00046, val_loss: 0.00142, lr: 6.27E-07, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:22:17,755]\u001b[0m Trial 47 finished with value: 0.6759391106545617 and parameters: {'embedding_dim': 449, 'num_filters': 494, 'hidden_dim': 283, 'dropout_p': 0.3247286479643003, 'lr': 6.269357965334842e-05}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00453, val_loss: 0.00320, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00350, val_loss: 0.00286, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00307, val_loss: 0.00264, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00290, val_loss: 0.00258, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00280, val_loss: 0.00253, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00270, val_loss: 0.00246, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00258, val_loss: 0.00241, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00249, val_loss: 0.00234, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00242, val_loss: 0.00227, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00231, val_loss: 0.00221, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00219, val_loss: 0.00214, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00212, val_loss: 0.00207, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00200, val_loss: 0.00203, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00191, val_loss: 0.00195, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00185, val_loss: 0.00191, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00176, val_loss: 0.00185, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00167, val_loss: 0.00181, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00164, val_loss: 0.00177, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00154, val_loss: 0.00174, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00150, val_loss: 0.00170, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00143, val_loss: 0.00167, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00135, val_loss: 0.00166, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00132, val_loss: 0.00163, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00127, val_loss: 0.00162, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00124, val_loss: 0.00160, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00118, val_loss: 0.00159, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00114, val_loss: 0.00158, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00110, val_loss: 0.00156, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00106, val_loss: 0.00155, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00104, val_loss: 0.00155, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00100, val_loss: 0.00153, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00093, val_loss: 0.00150, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00091, val_loss: 0.00149, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00088, val_loss: 0.00150, lr: 5.06E-05, _patience: 9\n",
            "Epoch: 35 | train_loss: 0.00084, val_loss: 0.00151, lr: 5.06E-05, _patience: 8\n",
            "Epoch: 36 | train_loss: 0.00082, val_loss: 0.00150, lr: 5.06E-05, _patience: 7\n",
            "Epoch: 37 | train_loss: 0.00081, val_loss: 0.00151, lr: 5.06E-05, _patience: 6\n",
            "Epoch: 38 | train_loss: 0.00076, val_loss: 0.00149, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00074, val_loss: 0.00149, lr: 5.06E-05, _patience: 9\n",
            "Epoch: 40 | train_loss: 0.00073, val_loss: 0.00149, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 41 | train_loss: 0.00069, val_loss: 0.00147, lr: 5.06E-05, _patience: 10\n",
            "Epoch: 42 | train_loss: 0.00067, val_loss: 0.00151, lr: 5.06E-05, _patience: 9\n",
            "Epoch: 43 | train_loss: 0.00065, val_loss: 0.00148, lr: 5.06E-05, _patience: 8\n",
            "Epoch: 44 | train_loss: 0.00063, val_loss: 0.00149, lr: 5.06E-05, _patience: 7\n",
            "Epoch: 45 | train_loss: 0.00061, val_loss: 0.00150, lr: 5.06E-05, _patience: 6\n",
            "Epoch: 46 | train_loss: 0.00059, val_loss: 0.00149, lr: 5.06E-05, _patience: 5\n",
            "Epoch: 47 | train_loss: 0.00057, val_loss: 0.00147, lr: 5.06E-06, _patience: 4\n",
            "Epoch: 48 | train_loss: 0.00054, val_loss: 0.00147, lr: 5.06E-06, _patience: 10\n",
            "Epoch: 49 | train_loss: 0.00053, val_loss: 0.00145, lr: 5.06E-06, _patience: 10\n",
            "Epoch: 50 | train_loss: 0.00052, val_loss: 0.00145, lr: 5.06E-06, _patience: 9\n",
            "Epoch: 51 | train_loss: 0.00052, val_loss: 0.00147, lr: 5.06E-06, _patience: 8\n",
            "Epoch: 52 | train_loss: 0.00052, val_loss: 0.00146, lr: 5.06E-06, _patience: 7\n",
            "Epoch: 53 | train_loss: 0.00050, val_loss: 0.00145, lr: 5.06E-06, _patience: 6\n",
            "Epoch: 54 | train_loss: 0.00051, val_loss: 0.00146, lr: 5.06E-06, _patience: 5\n",
            "Epoch: 55 | train_loss: 0.00051, val_loss: 0.00145, lr: 5.06E-07, _patience: 4\n",
            "Epoch: 56 | train_loss: 0.00051, val_loss: 0.00145, lr: 5.06E-07, _patience: 3\n",
            "Epoch: 57 | train_loss: 0.00051, val_loss: 0.00145, lr: 5.06E-07, _patience: 2\n",
            "Epoch: 58 | train_loss: 0.00051, val_loss: 0.00145, lr: 5.06E-07, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:24:46,158]\u001b[0m Trial 48 finished with value: 0.641850578803056 and parameters: {'embedding_dim': 294, 'num_filters': 445, 'hidden_dim': 308, 'dropout_p': 0.4418280205121402, 'lr': 5.056615745741886e-05}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00623, val_loss: 0.00314, lr: 3.99E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00337, val_loss: 0.00252, lr: 3.99E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00258, val_loss: 0.00206, lr: 3.99E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00204, val_loss: 0.00179, lr: 3.99E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00169, val_loss: 0.00171, lr: 3.99E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00140, val_loss: 0.00165, lr: 3.99E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00115, val_loss: 0.00157, lr: 3.99E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00090, val_loss: 0.00156, lr: 3.99E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00076, val_loss: 0.00153, lr: 3.99E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00064, val_loss: 0.00156, lr: 3.99E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00053, val_loss: 0.00162, lr: 3.99E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00044, val_loss: 0.00169, lr: 3.99E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00040, val_loss: 0.00179, lr: 3.99E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00034, val_loss: 0.00173, lr: 3.99E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00031, val_loss: 0.00176, lr: 3.99E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00025, val_loss: 0.00157, lr: 3.99E-05, _patience: 3\n",
            "Epoch: 17 | train_loss: 0.00020, val_loss: 0.00163, lr: 3.99E-05, _patience: 2\n",
            "Epoch: 18 | train_loss: 0.00019, val_loss: 0.00164, lr: 3.99E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "\u001b[32m[I 2021-07-10 22:25:40,684]\u001b[0m Trial 49 finished with value: 0.6863018900623078 and parameters: {'embedding_dim': 356, 'num_filters': 419, 'hidden_dim': 451, 'dropout_p': 0.4733659290881291, 'lr': 0.00039877990719003196}. Best is trial 32 with value: 0.7102877118012281.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiXpOQ2sc5e2",
        "outputId": "a95cd1b9-0574-4be5-8a06-3dd96aa31712"
      },
      "source": [
        "# MLFlow dashboard\n",
        "get_ipython().system_raw(\"mlflow server -h 0.0.0.0 -p 5000 --backend-store-uri $PWD/experiments/ &\")\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token(\"\")\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLflow Tracking UI: https://c39c622847dc.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "Q2lD_f0Yi8uS",
        "outputId": "10364272-c78a-4634-977a-8db966a7318e"
      },
      "source": [
        "# All trials\n",
        "trials_df = study.trials_dataframe()\n",
        "trials_df = trials_df.sort_values([\"value\"], ascending=False)  # sort by metric\n",
        "trials_df.head()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>value</th>\n",
              "      <th>datetime_start</th>\n",
              "      <th>datetime_complete</th>\n",
              "      <th>duration</th>\n",
              "      <th>params_dropout_p</th>\n",
              "      <th>params_embedding_dim</th>\n",
              "      <th>params_hidden_dim</th>\n",
              "      <th>params_lr</th>\n",
              "      <th>params_num_filters</th>\n",
              "      <th>user_attrs_f1</th>\n",
              "      <th>user_attrs_precision</th>\n",
              "      <th>user_attrs_recall</th>\n",
              "      <th>user_attrs_threshold</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>0.710288</td>\n",
              "      <td>2021-07-10 22:01:21.710400</td>\n",
              "      <td>2021-07-10 22:02:27.801826</td>\n",
              "      <td>0 days 00:01:06.091426</td>\n",
              "      <td>0.374602</td>\n",
              "      <td>472</td>\n",
              "      <td>402</td>\n",
              "      <td>0.000494</td>\n",
              "      <td>398</td>\n",
              "      <td>0.710288</td>\n",
              "      <td>0.849331</td>\n",
              "      <td>0.628755</td>\n",
              "      <td>0.332658</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>0.708135</td>\n",
              "      <td>2021-07-10 21:41:22.584840</td>\n",
              "      <td>2021-07-10 21:42:38.022625</td>\n",
              "      <td>0 days 00:01:15.437785</td>\n",
              "      <td>0.433708</td>\n",
              "      <td>473</td>\n",
              "      <td>505</td>\n",
              "      <td>0.000486</td>\n",
              "      <td>512</td>\n",
              "      <td>0.708135</td>\n",
              "      <td>0.856881</td>\n",
              "      <td>0.618026</td>\n",
              "      <td>0.346464</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>38</td>\n",
              "      <td>0.707382</td>\n",
              "      <td>2021-07-10 22:09:48.479380</td>\n",
              "      <td>2021-07-10 22:10:43.088947</td>\n",
              "      <td>0 days 00:00:54.609567</td>\n",
              "      <td>0.519586</td>\n",
              "      <td>420</td>\n",
              "      <td>322</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>353</td>\n",
              "      <td>0.707382</td>\n",
              "      <td>0.834607</td>\n",
              "      <td>0.635193</td>\n",
              "      <td>0.290364</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>0.705662</td>\n",
              "      <td>2021-07-10 21:55:27.826290</td>\n",
              "      <td>2021-07-10 21:56:18.820319</td>\n",
              "      <td>0 days 00:00:50.994029</td>\n",
              "      <td>0.389737</td>\n",
              "      <td>440</td>\n",
              "      <td>351</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>361</td>\n",
              "      <td>0.705662</td>\n",
              "      <td>0.827111</td>\n",
              "      <td>0.635193</td>\n",
              "      <td>0.290400</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>0.705156</td>\n",
              "      <td>2021-07-10 21:37:36.814178</td>\n",
              "      <td>2021-07-10 21:38:49.495839</td>\n",
              "      <td>0 days 00:01:12.681661</td>\n",
              "      <td>0.415083</td>\n",
              "      <td>492</td>\n",
              "      <td>420</td>\n",
              "      <td>0.000480</td>\n",
              "      <td>397</td>\n",
              "      <td>0.705156</td>\n",
              "      <td>0.840579</td>\n",
              "      <td>0.624464</td>\n",
              "      <td>0.296465</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    number     value  ... user_attrs_threshold     state\n",
              "32      32  0.710288  ...             0.332658  COMPLETE\n",
              "15      15  0.708135  ...             0.346464  COMPLETE\n",
              "38      38  0.707382  ...             0.290364  COMPLETE\n",
              "26      26  0.705662  ...             0.290400  COMPLETE\n",
              "11      11  0.705156  ...             0.296465  COMPLETE\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DDVzz88oSbB",
        "outputId": "1c9e7a5e-f78f-42a1-e6c4-8f1951c642d1"
      },
      "source": [
        "# Best trial\n",
        "print (f\"Best value (f1): {study.best_trial.value}\")\n",
        "print (f\"Best hyperparameters: {study.best_trial.params}\")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best value (f1): 0.7102877118012281\n",
            "Best hyperparameters: {'embedding_dim': 472, 'num_filters': 398, 'hidden_dim': 402, 'dropout_p': 0.37460230139713574, 'lr': 0.0004944035411985671}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGDCRdD4onzo",
        "outputId": "fef9f7fb-3407-4433-df6b-569b9d86ab3b"
      },
      "source": [
        "# Save best parameters\n",
        "params = {**args.__dict__, **study.best_trial.params}\n",
        "params[\"threshold\"] = study.best_trial.user_attrs[\"threshold\"]\n",
        "print (json.dumps(params, indent=2, cls=NumpyEncoder))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"char_level\": true,\n",
            "  \"filter_sizes\": [\n",
            "    1,\n",
            "    2,\n",
            "    3,\n",
            "    4,\n",
            "    5,\n",
            "    6,\n",
            "    7,\n",
            "    8,\n",
            "    9,\n",
            "    10\n",
            "  ],\n",
            "  \"batch_size\": 64,\n",
            "  \"embedding_dim\": 472,\n",
            "  \"num_filters\": 398,\n",
            "  \"hidden_dim\": 402,\n",
            "  \"dropout_p\": 0.37460230139713574,\n",
            "  \"lr\": 0.0004944035411985671,\n",
            "  \"num_epochs\": 200,\n",
            "  \"patience\": 10,\n",
            "  \"threshold\": 0.3326583206653595\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAQohscaqQFq",
        "outputId": "2c1181e7-1d52-48a5-9981-318a09ad7816"
      },
      "source": [
        "params"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 64,\n",
              " 'char_level': True,\n",
              " 'dropout_p': 0.37460230139713574,\n",
              " 'embedding_dim': 472,\n",
              " 'filter_sizes': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
              " 'hidden_dim': 402,\n",
              " 'lr': 0.0004944035411985671,\n",
              " 'num_epochs': 200,\n",
              " 'num_filters': 398,\n",
              " 'patience': 10,\n",
              " 'threshold': 0.33265832}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9YYSWJNtEJz"
      },
      "source": [
        "params['threshold']=str(params['threshold'])"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG8g9rdMqtC1",
        "outputId": "bcd2f021-cf6e-4710-a890-5d38670227ba"
      },
      "source": [
        "tempfile.TemporaryDirectory()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TemporaryDirectory '/tmp/tmp131fct1a'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccM8nCV8pTei"
      },
      "source": [
        "import os\n",
        "os.makedirs(\"data_new\", exist_ok=True)\n",
        "with open(\"data_new/best_params.json\", 'w', encoding='utf-8') as f:\n",
        "    json.dump(params, f, indent=2)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3BuQT8kqZBY"
      },
      "source": [
        "plams = load_dict(filepath=\"data_new/best_params.json\")"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5Zb10l0uNyF",
        "outputId": "c6760f89-fea2-44dc-9a69-c2cc99ebf0df"
      },
      "source": [
        "plams"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 64,\n",
              " 'char_level': True,\n",
              " 'dropout_p': 0.37460230139713574,\n",
              " 'embedding_dim': 472,\n",
              " 'filter_sizes': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
              " 'hidden_dim': 402,\n",
              " 'lr': 0.0004944035411985671,\n",
              " 'num_epochs': 200,\n",
              " 'num_filters': 398,\n",
              " 'patience': 10,\n",
              " 'threshold': '0.33265832'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZDaZXm1uQTg"
      },
      "source": [
        "plams['threshold'] =float(plams['threshold'])"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiDlJszyupFL",
        "outputId": "f3bc845c-3661-4683-c64b-d122a30e8171"
      },
      "source": [
        "plams"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 64,\n",
              " 'char_level': True,\n",
              " 'dropout_p': 0.37460230139713574,\n",
              " 'embedding_dim': 472,\n",
              " 'filter_sizes': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
              " 'hidden_dim': 402,\n",
              " 'lr': 0.0004944035411985671,\n",
              " 'num_epochs': 200,\n",
              " 'num_filters': 398,\n",
              " 'patience': 10,\n",
              " 'threshold': 0.33265832}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTVy72lmurKA"
      },
      "source": [
        "if 0.312 > plams['threshold']:\n",
        "  print ('ek')"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7qnWqbeu4PR",
        "outputId": "0ff7a792-60bf-4ccc-e2d4-6d88eab769b6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTAjvHsAwUAs"
      },
      "source": [
        "with open(\"/content/drive/My Drive/data/best_params.json\", 'w', encoding='utf-8') as f:\n",
        "    json.dump(plams, f, indent=2)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws8Fn-b7xqK5"
      },
      "source": [
        "#ceck = json.load(\"/content/drive/My Drive/data/best_params.json\")\n",
        "\n",
        "with open(\"/content/drive/My Drive/data/best_params.json\") as jsonFile:\n",
        "    jsonObject = json.load(jsonFile)\n",
        "    jsonFile.close()"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM5FJHYbzCt9",
        "outputId": "601daaec-80c0-4185-9369-4f69b6f10ab1"
      },
      "source": [
        "jsonObject"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 64,\n",
              " 'char_level': True,\n",
              " 'dropout_p': 0.37460230139713574,\n",
              " 'embedding_dim': 472,\n",
              " 'filter_sizes': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
              " 'hidden_dim': 402,\n",
              " 'lr': 0.0004944035411985671,\n",
              " 'num_epochs': 200,\n",
              " 'num_filters': 398,\n",
              " 'patience': 10,\n",
              " 'threshold': 0.33265832}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzN8tOIyz_-P",
        "outputId": "42998438-1dee-4492-8f4d-7bebd30c4590"
      },
      "source": [
        "jsonObject['threshold']"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33265832"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PyuIPMa0IEA",
        "outputId": "287e980c-3337-412b-9fb8-be1e77199e6d"
      },
      "source": [
        "if 0.387 > jsonObject['threshold']:\n",
        "  print ('ek')"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ek\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVlJSQii0SIA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}